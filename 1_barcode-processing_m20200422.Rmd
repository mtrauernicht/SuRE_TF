---
title: "Barcode processing"
author: "Max Trauernicht"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output: 
  html_document:
    theme: journal #cerulean
    highlight: monochrome
    toc: true
    toc_float: true
    code_folding: show
  editor_options:
    chunk_output_type: console
---

# knitr document van Steensel lab

# TF reporter barcode processing

# Introduction
18,000 TF reporters on pMT02 were transfected into mESCs and NPCs (in total 7 different conditions), sequencing data yielded barcode counts of these experiments. These counts will be processed in this script. 

## Description of Data
How to make a good rendering table: 
```{r table1, echo=FALSE, message=FALSE, warnings=FALSE, results='asis'}
tabl <- "
| column1	|	column2	|	column3	|	
|----|----|----|
|1	|	2	|	3	|	
|a	|	b	|	c	|	
"
cat(tabl) # output the table in a format good for HTML/PDF/docx conversion
```

# Data processing
## Path, Libraries, Parameters and Useful Functions
```{r setup}
knitr::opts_chunk$set(echo = TRUE)
StartTime <-Sys.time()

# 8-digit Date tag:
Date <- substr(gsub("-","",Sys.time()),1,8) 
# libraries:
library(data.table)
library(plyr)
library(stringr)
library(ggpubr)
library(GGally)
library(vwr)
library(dplyr)
library(tibble)
library(plotly)
library(ggbeeswarm)
library(haven)
library(readr)
library(parallel)
library(RColorBrewer)
library(gridExtra)
```

### Custom functions
Functions used thoughout this script.
```{r}
SetFileName <- function(filename, initials) {
  # Set filename with extension and initials to make filename with date integrated.
  filename <- substitute(filename)
  initials <- substitute(initials)
  filename <- paste0(initials, Date, filename)
  filename
}


# From Fede:
# ggpairs custom functions
corColor <- function(data, mapping, color = I("black"), sizeRange = c(1, 3), ...) {

  x   <- eval_data_col(data, mapping$x)
  y   <- eval_data_col(data, mapping$y)
  r   <- cor(x, y, "pairwise.complete.obs")
  rt  <- format(r, digits = 3)
  tt  <- as.character(rt)
  cex <- max(sizeRange)

  # helper function to calculate a useable size
  percent_of_range <- function(percent, range) {
    percent * diff(range) + min(range, na.rm = TRUE)
  }

  # plot correlation coefficient
  p <- ggally_text(label = tt, mapping = aes(), xP = 0.5, yP = 0.5,
                   size = I(percent_of_range(cex * abs(r), sizeRange)), color = color, ...) +
    theme(panel.grid.minor=element_blank(),
          panel.grid.major=element_blank())

  corColors <- RColorBrewer::brewer.pal(n = 7, name = "RdYlBu")[2:6]

  if (r <= boundaries[1]) {
    corCol <- corColors[1]
  } else if (r <= boundaries[2]) {
    corCol <- corColors[2]
  } else if (r < boundaries[3]) {
    corCol <- corColors[3]
  } else if (r < boundaries[4]) {
    corCol <- corColors[4]
  } else {
    corCol <- corColors[5]
  }

  p <- p +
    theme(panel.background = element_rect(fill = corCol))

  return(p)
}
```


## Data import
```{r data import, out.width= "100%", fig.align= "center", echo=FALSE, warning= FALSE}
# Import barcode counts per experiment
bc_files = list.files('/DATA/usr/m.trauernicht/projects/tf_activity_reporter/data/SuRE_TF_1/results_e3_s1/',
                       full.names=T, patter='*_barcode_counts.tsv')
bc_list <- lapply(bc_files, fread, header = FALSE)
names(bc_list)<- gsub('.*//(.*?)_[CGAT]{8}.*_barcode_counts.tsv', 
                                    '\\1', 
                                    bc_files)

# Import barcode annotation
bc_annotation <- read.csv("/DATA/usr/m.trauernicht/projects/tf_activity_reporter/data/SuRE_TF_1/TF-reporter_library_design/output/mt20191218_tf-array.csv", header = T)
bc_annotation$TF <- as.character(bc_annotation$TF) 
bc_annotation$TF[bc_annotation$TF == "ctrl"] <- "hPGK"

# Manually check clustering 
x <- read_table("/DATA/usr/m.trauernicht/projects/tf_activity_reporter/data/SuRE_TF_1/bartender/bc_2i_neg_LIF_r1_CGATGTAT_S98_conv_barcode.txt", col_names = F)
y <- read_csv("/DATA/usr/m.trauernicht/projects/tf_activity_reporter/data/SuRE_TF_1/bartender/2i_neg_LIF_r1_CGATGTAT_S98_cluster_barcode.csv", col_names = F)

barcodes <- bc_annotation$barcode
```

# Analysis

## Compare bartender with starcode
```{r cluster_compare, out.width= "100%", fig.align= "center", echo=FALSE, warning= FALSE}
# Generate long dfs
for (i in 1:22) {
  if (i == 1) {
  bc_df <- data.frame(bc_list[i])
  bc_df[3] <- names(bc_list[i])
  names(bc_df) <- c("barcode", "count", "name")
  bc_df <- reshape2::dcast(bc_df, barcode ~ name, value.var = "count")
  }
  else {
  bc_df_i <- data.frame(bc_list[i])
  bc_df_i[3] <- names(bc_list[i])
  names(bc_df_i) <- c("barcode", "count", "name")
  bc_df_i <- reshape2::dcast(bc_df_i, barcode ~ name, value.var = "count")
  bc_df <- merge(bc_df, bc_df_i, all = T)
  }
}


# Import starcode data
bartender_files = list.files('/DATA/usr/m.trauernicht/projects/tf_activity_reporter/data/SuRE_TF_1/bartender/',
                       full.names=T, patter='*_cluster_d3_barcode.csv')
bartender_list <- lapply(bartender_files, fread, header = FALSE)
names(bartender_list)<- gsub('.*//(.*?)_[CGAT]{8}.*_cluster_d3_barcode.csv',
                                    '\\1',
                                    bartender_files)


## Convert lists to data frames and reshape
for (i in 1:22) {
  if (i == 1) {
  bartender_df <- data.frame(bartender_list[i])
  bartender_df <- bartender_df[-1,]
  names(bartender_df) <- c("barcode", "count", "cluster")
  bartender_df$count <- as.numeric(bartender_df$count)
  bartender_df$bc_counts <- ave(bartender_df$count, bartender_df$cluster, FUN = function(x) sum(x))
  bartender_df <- bartender_df %>% group_by(cluster) %>% top_n(1, count)
  bartender_df$name <- names(bartender_list[i])
  bartender_df <- bartender_df[,c(-2,-3)]
  bartender_df <- reshape2::dcast(bartender_df, barcode ~ name, value.var = "bc_counts")
  }
  else {
  bartender_df_i <- data.frame(bartender_list[i])
  bartender_df_i <- bartender_df_i[-1,]
  names(bartender_df_i) <- c("barcode", "count", "cluster")
  bartender_df_i$count <- as.numeric(bartender_df_i$count)
  bartender_df_i$bc_counts <- ave(bartender_df_i$count, bartender_df_i$cluster, FUN = function(x) sum(x))
  bartender_df_i <- bartender_df_i %>% group_by(cluster) %>% top_n(1, count)
  bartender_df_i$name <- names(bartender_list[i])
  bartender_df_i <- bartender_df_i[,c(-2,-3)]
  bartender_df_i <- reshape2::dcast(bartender_df_i, barcode ~ name, value.var = "bc_counts")
  bartender_df <- merge(bartender_df, bartender_df_i, all = T)
  }
}


bc_annotation$seq <- paste(bc_annotation$Primer1_seq, bc_annotation$motif1, bc_annotation$Space1,
                                bc_annotation$motif2,bc_annotation$Space2, bc_annotation$motif3,
                                bc_annotation$Space3, bc_annotation$motif4, bc_annotation$Distance_seq,
                                bc_annotation$Promoter_sequence, bc_annotation$S1_primer,
                                bc_annotation$barcode, bc_annotation$Primer2_seq, sep = "")
bc_annotation <- bc_annotation %>% select(TF, Spacing, Distance, Barcode, Promoter, Background,
                                          barcode, seq)
bc_df <- merge(bc_df, bc_annotation, all = T)
bartender_df <- merge(bartender_df, bc_annotation, all = T)
bc_df <- bc_df[!is.na(bc_df$seq),] %>% select(-TF, -Spacing, -Distance, -Barcode,
                                                                -Promoter, -Background, -seq)
bartender_df <- bartender_df[!is.na(bartender_df$seq),]%>% select(-TF, -Spacing, -Distance, -Barcode,
                                                                -Promoter, -Background, -seq)

bc_df_long <- melt(bc_df, id.vars = "barcode",
              variable.name = "condition", value.name = "starcode_counts")

bartender_long <- melt(bartender_df, id.vars = "barcode",
              variable.name = "condition", value.name = "bartender_counts")

comparison_long <- merge(bc_df_long, bartender_long, all = T)

comparison_long[is.na(comparison_long)] <- 0

sp <- ggscatter(comparison_long, x = "starcode_counts", y = "bartender_counts",
   add = "reg.line",
   add.params = list(color = "blue", fill = "lightgray"), title = "barcode counts starcode vs. bartender",
   conf.int = TRUE, ylab = "barcode counts bartender", xlab = "barcode counts starcode")
sp + stat_cor(method = "pearson", label.x = 3, label.y = 40000) + geom_abline(linetype = "dashed")
```

# Conlusion barcode clustering:
- optimal starcode settings: levenshtein distance of 1
- optimal bartender settings: hamming distance of 2
- starcode and bartender perform equally well - starcode a bit better
- next time design barcodes requiring levenshtein distance of 3


## Add barcode annotation to barcode counts & extract first bc read count information
```{r annotation, out.width= "100%", fig.align= "center", echo=FALSE, warning= FALSE}
# Transform lists to df
## Count barcodes - ignore barcode clustering
# for (i in 1:22) {
#   if (i == 1) {
#   bc_df <- data.frame(bc_list[i])
#   bc_df[2] <- names(bc_list[i])
#   names(bc_df) <- c("barcode", "name")
#   bc_df <- reshape2::dcast(bc_df, barcode ~ name) # This will count the barcodes
#   }
#   else {
#   bc_df_i <- data.frame(bc_list[i])
#   bc_df_i[2] <- names(bc_list[i])
#   names(bc_df_i) <- c("barcode", "name")
#   bc_df_i <- reshape2::dcast(bc_df_i, barcode ~ name)
#   bc_df <- merge(bc_df, bc_df_i, all = T)
#   }
# }




## Convert lists to data frames and reshape
for (i in 1:22) {
  if (i == 1) {
  bc_df <- data.frame(bc_list[i])
  bc_df[3] <- names(bc_list[i])
  names(bc_df) <- c("barcode", "count", "name")
  bc_df <- reshape2::dcast(bc_df, barcode ~ name, value.var = "count")
  }
  else {
  bc_df_i <- data.frame(bc_list[i])
  bc_df_i[3] <- names(bc_list[i])
  names(bc_df_i) <- c("barcode", "count", "name")
  bc_df_i <- reshape2::dcast(bc_df_i, barcode ~ name, value.var = "count")
  bc_df <- merge(bc_df, bc_df_i, all = T)
  }
}

# Match TF reporter to barcode
## Match barcode sequences from sequencing with barcodes from oligo design
bc_df <- merge(bc_df, bc_annotation, all = T)
bc_df$TF[bc_df$TF == "ctrl"] <- as_factor("hPGK")

## Include TF reporter length (correlation with pDNA counts?)
bc_df$length <- nchar(bc_df$seq)



## Make a graph to show total reads per condition
bc_df[,2:23][is.na(bc_df[,2:23])] <- 0
bc_df_new <- bc_df
bc_df_new_match <- bc_df_new[!is.na(bc_df_new$seq),]
bc_df_new_match[,2:23] <- as.numeric(unlist(bc_df_new_match[,2:23]))
experimental_reads <- data.frame(colSums(bc_df_new_match[,c(-1, -24:-31)])) %>% 
  tibble::rownames_to_column()
names(experimental_reads) <- c("experiment", "reads")
experimental_reads$mean <- mean(experimental_reads$reads)

p <- ggplot(data = experimental_reads, aes(y = reads, x = reorder(experiment, -reads))) + 
  geom_bar(stat = "identity") + xlab("Experimental condition") + ylab("Total read counts per experiment") +
  labs(title = "Total barcode reads per condition", 
       subtitle = paste("Mean total reads: ", round(experimental_reads$mean,2), "x", sep = "")) + 
  theme_classic() + theme(axis.text.x = element_text(angle = 90, hjust = 1.0, vjust = 0))

p + geom_line(aes(y = mean, group = mean), linetype = "dashed")

## Mean reads per condition are more informative
experimental_reads_mean <- data.frame(colMeans(bc_df_new_match[,c(-1, -24:-31)])) %>% 
  tibble::rownames_to_column()
names(experimental_reads_mean) <- c("experiment", "reads")
experimental_reads_mean$mean <- mean(experimental_reads_mean$reads)

p <- ggplot(data = experimental_reads_mean, aes(y = reads, x = reorder(experiment, -reads))) + 
  geom_bar(stat = "identity") + xlab("Experimental condition") + ylab("Mean read counts per experiment") +
  labs(title = "Mean barcode reads per condition", 
       subtitle = paste("Mean read count: ", round(experimental_reads_mean$mean,2), "x", sep = "")) + 
  theme_classic() + theme(axis.text.x = element_text(angle = 90, hjust = 1.0, vjust = 0))

p + geom_line(aes(y = mean, group = mean), linetype = "dashed")
```


## Get a closer look at unmatched barcodes 
```{r pie unmatch, out.width= "100%", fig.align= "center", echo=FALSE, warning= FALSE}
# Get plots for filtered fraction
bc_df_long <- melt(bc_df, id.vars = c("barcode","TF", "Spacing", "Distance", "Barcode", 
                                 "Promoter", "Background", "seq", "length"), 
              variable.name = "condition", value.name = "bc_counts")
bc_df_long$bc_counts[is.na(bc_df_long$bc_counts)] <- 0


## Identify the unmapped fraction
bc_df_nomatch <- bc_df_long[is.na(bc_df_long$seq),]
bc_df_match <- bc_df_long[!is.na(bc_df_long$seq),]
bc_df_match$bc_counts <- as.numeric(bc_df_match$bc_counts)
bc_df_nomatch$bc_counts <- as.numeric(bc_df_nomatch$bc_counts)
bc_df_nomatch$bc_sum <- ave(bc_df_nomatch$bc_counts, bc_df_nomatch$barcode, FUN = function(x) sum(x))
bc_df_match$bc_sum <- ave(bc_df_match$bc_counts, bc_df_match$barcode, FUN = function(x) sum(x))
bc_df_nomatch <- bc_df_nomatch %>% select(barcode, bc_sum) %>% unique()
bc_df_match <- bc_df_match %>% select(barcode, bc_sum) %>% unique()
bc_df_nomatch$mean_coverage <- bc_df_nomatch$bc_sum / 22
bc_df_match$mean_coverage <- bc_df_match$bc_sum / 22

ggplot(data = bc_df_nomatch, aes(x = mean_coverage)) + 
  geom_density() + xlab("mean coverage") + 
  xlim(1,100) +
  labs(title = "barcode reads - unmatched barcodes") +
  theme_classic()

ggplot(data = bc_df_match, aes(x = mean_coverage)) + 
  geom_density() + xlab("mean coverage") + 
  xlim(1,100) +
  labs(title = "barcode reads - matched barcodes") +
  theme_classic()



## How many barcodes are unmatched?
n_match <- nrow(bc_df_match)
n_nomatch <- nrow(bc_df_nomatch)

# Create donut chart
data <- data.frame(
  lbls=c("matched:", "unmatched:"),
  count=c(n_match, n_nomatch)
)
 
# Compute percentages
data$fraction <- data$count / sum(data$count)
data$percentage <- data$fraction * 100


# Compute the cumulative percentages (top of each rectangle)
data$ymax <- cumsum(data$fraction)


# Compute the cumulative percentages (top of each rectangle)
data$ymax <- cumsum(data$fraction)

# Compute the bottom of each rectangle
data$ymin <- c(0, head(data$ymax, n=-1))

# Compute label position
data$labelPosition <- (data$ymax + data$ymin) / 2

# Compute a good label
data$label <- paste0(data$lbls, "\n", round(data$percentage), "%")

# Make the plot
ggplot(data, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=lbls)) +
  geom_rect() +
  geom_text(x=2, aes(y=labelPosition, label=label, color=lbls), size=5) + # x here controls label position (inner / outer)
  scale_fill_manual(values = c("#1B998B", "#2D3047")) +
  scale_color_manual(values = c("#1B998B", "#2D3047")) +
  labs(title = "percentage of barcodes matched") +
  coord_polar(theta="y") +
  xlim(c(0, 4)) +
  theme_void() +
  theme(legend.position = "none")




## How many reads are unmatched?
n_match_reads <- sum(bc_df_match$bc_sum)
bc_df_nomatch$bc_sum[is.na(bc_df_nomatch$bc_sum)] <- 0
n_nomatch_reads <- sum(bc_df_nomatch$bc_sum)

# Create donut chart
data <- data.frame(
  lbls=c("matched:", "unmatched:"),
  count=c(n_match_reads, n_nomatch_reads)
)
 
# Compute percentages
data$fraction <- data$count / sum(data$count)
data$percentage <- data$fraction * 100


# Compute the cumulative percentages (top of each rectangle)
data$ymax <- cumsum(data$fraction)


# Compute the cumulative percentages (top of each rectangle)
data$ymax <- cumsum(data$fraction)

# Compute the bottom of each rectangle
data$ymin <- c(0, head(data$ymax, n=-1))

# Compute label position
data$labelPosition <- (data$ymax + data$ymin) / 2

# Compute a good label
data$label <- paste0(data$lbls, "\n", round(data$percentage), "%")

# Make the plot
ggplot(data, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=lbls)) +
  geom_rect() +
  geom_text(x=2, aes(y=labelPosition, label=label, color=lbls), size=5) + # x here controls label position (inner / outer)
  scale_fill_manual(values = c("#1B998B", "#2D3047")) +
  scale_color_manual(values = c("#1B998B", "#2D3047")) +
  labs(title = "percentage of barcode reads matched") +
  coord_polar(theta="y") +
  xlim(c(0, 4)) +
  theme_void() +
  theme(legend.position = "none")
```


## We still have a lot of unmatched barcodes - Match unmatched barcodes to designed barcodes
```{r barcode match, out.width= "100%", fig.align= "center", echo=FALSE, warning= FALSE}
# # Where could these unmatched, highly active barcodes come from?
# # Calculate levenshtein distance from barcodes in design to sequenced non-matched barcodes - ilter non-matched barcodes to only include active ones
# bc_nomatch <- bc_df_nomatch$barcode[bc_df_nomatch$bc_sum > 50]
# bc_match <- bc_annotation$barcode
# 
# # For each barcode in the deisgn, calculate the levenshtein distance to each non-matched barcode
# n <- 0
# for (i in 1:17580) {
#   if (i == 1) {
#     l <- data.frame(levenshtein.distance(bc_match[i], bc_nomatch))
#   }
#   else {
#     l[i] <- levenshtein.distance(bc_match[i], bc_nomatch)
# 
#     # Keep track of the progress
#     n <- n + length(i)
#     percent <- (n / 17580)*100
#     progress <- paste("progress:", percent, "%")
#     if (percent %% 10 == 0) {
#     print(progress)
#     }
#   }
# 
# }
# names(l) <- bc_match
# 
# # Only keep sequences with levenshtein distance of 1
# lev <- l
# lev <- lev[rowSums(lev == 1) == 1,colSums(lev == 1) >= 1]
# 
# 
# # Match barcodes with levenshtein distance of 1
# index <- data.frame(which(lev==1, arr.ind=TRUE))
# index <- tibble::rownames_to_column(index)
# for (i in 1:nrow(index)) {
#   index$colname[i] <- colnames(lev)[index$col[i]]
# }
# index <- index %>% select(rowname, colname)
# names(index) <- c("non_match_barcode", "match_barcode")
# 
# 
# # Calculate correlation of each non-matched barcode to the two matched barcodes -> choose highest correlation bc
# # Correlation between matched and unmatched barcode counts
# match_bc_df <- bc_df[bc_df$barcode %in% index$match_barcode,c(1:23)]
# match_bc_df <- melt(match_bc_df, id.vars = c("barcode"), variable.name = "condition", value.name = "bc_counts")
# names(match_bc_df) <- c("match_barcode", "condition", "match_counts")
# match_bc_df <- merge(match_bc_df, index, all = T)
# match_bc_df <- match_bc_df %>% select(-non_match_barcode)
# 
# non_match_bc_df <- bc_df[bc_df$barcode %in% index$`non_match_barcode`,c(1:23)]
# setnames(non_match_bc_df, old = "barcode", new = "non_match_barcode")
# non_match_bc_df <- merge(non_match_bc_df, index, all = T)
# non_match_bc_df <- non_match_bc_df %>% group_by(match_barcode) %>% mutate(rep = seq_len( n() ) )
# non_match_bc_df <- melt(non_match_bc_df, id.vars = c("non_match_barcode", "rep", "match_barcode"), variable.name = "condition", value.name = "bc_counts")
# cor_bc_reads <- merge(match_bc_df, non_match_bc_df, all = T)
# cor_bc_reads[is.na(cor_bc_reads)] <- 0
# 
# # This method is not sensitive for data with very little counts - remove those
# cor_bc_reads$bc_counts <- as.numeric(cor_bc_reads$bc_counts)
# cor_bc_reads$match_counts <- as.numeric(cor_bc_reads$match_counts)
# cor_bc_reads$sum_counts <- ave(cor_bc_reads$bc_counts, cor_bc_reads$rep, cor_bc_reads$match_barcode,
#                                FUN = function(x) sum(x))
# cor_bc_reads <- cor_bc_reads[cor_bc_reads$sum_counts > 1000,]
# 
# cor_bc_reads$copies <- ave(cor_bc_reads$rep, cor_bc_reads$match_barcode,
#                                FUN = function(x) length(unique(x)))
# 
# cor_bc_reads <- unique(cor_bc_reads)
# 
# # For each barcode compute correlation of matched vs. unmatched rep 1-4
# n <- 0
# 
# for (i in unique(cor_bc_reads$non_match_barcode)) {
#     cor_bc_reads$cor[cor_bc_reads$non_match_barcode == i] <-
#       cor(cor_bc_reads$match_counts[cor_bc_reads$non_match_barcode == i],
#           cor_bc_reads$bc_counts[cor_bc_reads$non_match_barcode == i])
# 
#     n <- n + length(i)
#     percent <- (n / length(unique(cor_bc_reads$non_match_barcode)))*100
#     progress <- paste("progress:", percent, "%")
#     if (percent %% 10 == 0) {
#     print(progress)
#   }
# }
# 
# 
# # Filter out those with a weak correlation - this automatically keeps the correct ones with many counts
# cor_bc_reads[is.na(cor_bc_reads)] <- 0
# cor_bc_reads_low <- cor_bc_reads[cor_bc_reads$cor <= 0.75,]
# cor_bc_reads <- cor_bc_reads[cor_bc_reads$cor > 0.75,]
# cor_bc_reads <- cor_bc_reads %>% select(-condition, -match_counts, -bc_counts)
# cor_bc_reads <- unique(cor_bc_reads)
# 
# 
# 
# # Correlation between matched and unmatched barcode counts
# index_3 <- cor_bc_reads
# match_bc_df <- bc_df[bc_df$barcode %in% index_3$match_barcode,c(1:23)]
# match_bc_df <- melt(match_bc_df, id.vars = c("barcode"), variable.name = "condition", value.name = "bc_counts")
# names(match_bc_df) <- c("match_barcode", "condition", "match_counts")
# match_bc_df <- merge(match_bc_df, index_3, all = T)
# 
# non_match_bc_df <- bc_df[bc_df$barcode %in% index_3$non_match_barcode,c(1:23)]
# non_match_bc_df <- melt(non_match_bc_df, id.vars = c("barcode"), variable.name = "condition", value.name = "bc_counts")
# names(non_match_bc_df) <- c("non_match_barcode", "condition", "non_match_counts")
# non_match_bc_df <- merge(non_match_bc_df, index_3, all = T)
# non_match_bc_df <- non_match_bc_df %>% select(-`non_match_barcode`)
# cor_bc_reads <- merge(match_bc_df, non_match_bc_df, all = T)
# cor_bc_reads[is.na(cor_bc_reads)] <- 0
# 
# sp <- ggscatter(cor_bc_reads, x = "match_counts", y = "non_match_counts",
#    add = "reg.line",
#    add.params = list(color = "blue", fill = "lightgray"), title = "correlation matched vs. unmatched barcodes",
#    conf.int = TRUE, ylab = "bc counts unmatched", xlab = "bc counts matched")
# sp + stat_cor(method = "pearson", label.x = 3, label.y = 6000) + geom_abline(linetype = "dashed")
# 
# 
# 
# cor_bc_reads <- cor_bc_reads %>% select(match_barcode, non_match_barcode) %>% unique()
# 
# 
# # Change barcodes in bc_df to matched barcodes
# n <- 0
# 
# bc_nomatch_low <- bc_df_nomatch$barcode[bc_df_nomatch$bc_sum <= 100]
# bc_df <- subset(bc_df, !(bc_df$barcode %in% bc_nomatch_low))
# 
# for (i in unique(bc_df$barcode)) {
#   if (i %in% cor_bc_reads$non_match_barcode) {
#     k <- which(grepl(i, cor_bc_reads$non_match_barcode))
#     bc_df$barcode[bc_df$barcode == i] <- cor_bc_reads$match_barcode[k]
# 
#     n <- n + length(i)
#     percent <- (n / length(unique(bc_df$barcode))*100)
#     progress <- paste("progress:", percent, "%")
#     if (percent %% 10 == 0) {
#     print(progress)
#     }
#   }
# }
# 
# # Sum up identical barcodes
# bc_df[,2:23][is.na(bc_df[,2:23])] <- 0
# bc_df <- merge(bc_df, bc_annotation, by = "barcode", all = T)
# bc_df <- bc_df %>% select(-TF.x, -Spacing.x, -Distance.x, -Barcode.x, -Promoter.x, -Background.x, -seq.x)
# setnames(bc_df,
#          old = c("TF.y", "Spacing.y", "Distance.y", "Barcode.y", "Promoter.y", "Background.y", "seq.y" ),
#          new = c("TF", "spacing", "distance", "bc-number", "promoter", "background", "seq"))
# bc_df$length <- nchar(bc_df$seq)
# 
# bc_df <- ddply(bc_df,~barcode + length + TF + spacing + distance + `bc-number` + promoter +
#                    background + seq,
#                  summarise, `2i_neg_LIF_r1` = sum(`2i_neg_LIF_r1`),
#             `2i_neg_LIF_r2` = sum(`2i_neg_LIF_r2`),
#             `2i_neg_LIF_r3` = sum(`2i_neg_LIF_r3`),
#             `2i_pos_LIF_r1` = sum(`2i_pos_LIF_r1`),
#             `2i_pos_LIF_r2` = sum(`2i_pos_LIF_r2`),
#             `2i_pos_LIF_r3` = sum(`2i_pos_LIF_r3`),
#             `LIF_pos_CH_r2` = sum(`LIF_pos_CH_r2`),
#             `LIF_pos_CH_r3` = sum(`LIF_pos_CH_r3`),
#             `LIF_pos_PD_r1` = sum(`LIF_pos_PD_r1`),
#             `LIF_pos_PD_r2` = sum(`LIF_pos_PD_r2`),
#             `LIF_pos_PD_r3` = sum(`LIF_pos_PD_r3`),
#             `N2B27_r1` = sum(`N2B27_r1`),
#             `N2B27_r2` = sum(`N2B27_r2`),
#             `N2B27_r3` = sum(`N2B27_r3`),
#             `NPC_r1` = sum(`NPC_r1`),
#             `NPC_r2` = sum(`NPC_r2`),
#             `NPC_r3` = sum(`NPC_r3`),
#             `pDNA_1` = sum(`pDNA_1`),
#             `pDNA_2` = sum(`pDNA_2`),
#             `vitA_r1` = sum(`vitA_r1`),
#             `vitA_r2` = sum(`vitA_r2`),
#             `vitA_r3` = sum(`vitA_r3`))
# 
# # As the levenshtein step needs a lot of time, I will run it once and then export and import it again
# filename <- SetFileName("_bc_df_levenshtein", "mt")
# setwd("/DATA/usr/m.trauernicht/projects/tf_activity_reporter/data/SuRE_TF_1/results/")
# write.csv(bc_df, file = paste(filename,".csv", sep = ""), row.names = F)
```
### Conclusion barcode clustering:
- I manually added barcodes with high correlation and levenshtein distance of 1 to 1 barcode to get more reads

## Check again how many bc reads per experiment we have
```{r read count 2, out.width= "100%", fig.align= "center", echo=FALSE, warning= FALSE}
## Make a graph to show the previously calculated reads per condition
bc_df <- read.csv("/DATA/usr/m.trauernicht/projects/tf_activity_reporter/data/SuRE_TF_1/results/mt20200504_bc_df_levenshtein.csv", header = T)
bc_df_match <- bc_df[!is.na(bc_df$seq),]
experimental_reads_2 <- data.frame(colSums(bc_df_match[,c(-1:-9)])) %>% 
  tibble::rownames_to_column()
names(experimental_reads_2) <- c("experiment", "reads_2")
experimental_reads_2$experiment <- gsub("^X", "", experimental_reads_2$experiment)
experimental_reads_2 <- merge(experimental_reads, experimental_reads_2, all = T)
experimental_reads_2$dif <- experimental_reads_2$reads_2 - experimental_reads$reads
experimental_reads_2$mean <- mean(experimental_reads_2$dif)

p <- ggplot(data = experimental_reads_2, aes(y = dif, x = reorder(experiment, -dif))) + 
  geom_bar(stat = "identity") + xlab("Experimental condition") + ylab("Total barcodes added") +
  labs(title = "Additional barcodes per experiment through barcode matching", 
       subtitle = paste("Mean added reads: ", round(experimental_reads_2$mean,2), "x", sep = "")) + 
  theme_classic() + theme(axis.text.x = element_text(angle = 90, hjust = 1.0, vjust = 0))

p + geom_line(aes(y = mean, group = mean), linetype = "dashed")

## Mean reads per condition are more informative
experimental_reads_mean_2 <- data.frame(colMeans(bc_df_match[,c(-1:-9)])) %>% 
  tibble::rownames_to_column()
names(experimental_reads_mean_2) <- c("experiment", "reads_2")
experimental_reads_mean_2$experiment <- gsub("^X", "", experimental_reads_mean_2$experiment)
experimental_reads_mean_2 <- merge(experimental_reads_mean, experimental_reads_mean_2, all = T)
experimental_reads_mean_2$dif <- experimental_reads_mean_2$reads_2 - experimental_reads_mean_2$reads
experimental_reads_mean_2$mean <- mean(experimental_reads_mean_2$dif)

p <- ggplot(data = experimental_reads_mean_2, aes(y = dif, x = reorder(experiment, -dif))) + 
  geom_bar(stat = "identity") + xlab("Experimental condition") + ylab("Mean barcodes added") +
  labs(title = "Mean barcodes added per reporter (in each condition)", 
       subtitle = paste("Mean barcodes added : ", round(experimental_reads_mean_2$mean,2), "x", sep = "")) + 
  theme_classic() + theme(axis.text.x = element_text(angle = 90, hjust = 1.0, vjust = 0))

p + geom_line(aes(y = mean, group = mean), linetype = "dashed")
```




## Check again how many unmatched barcodes are left
```{r pie 2, out.width= "100%", fig.align= "center", echo=FALSE, warning= FALSE}
# Get plots for filtered fraction
bc_df_long <- melt(bc_df, id.vars = c("barcode","TF", "spacing", "distance", "bc.number", 
                                 "promoter", "background", "seq", "length"), 
              variable.name = "condition", value.name = "bc_counts")
bc_df_long$bc_counts[is.na(bc_df_long$bc_counts)] <- 0


## Identify which barcodes take up the reads in the unmapped fraction
bc_df_nomatch <- bc_df_long[is.na(bc_df_long$seq),]
bc_df_match <- bc_df_long[!is.na(bc_df_long$seq),]
bc_df_nomatch$bc_sum <- ave(bc_df_nomatch$bc_counts, bc_df_nomatch$barcode, FUN = function(x) sum(x))
bc_df_match$bc_sum <- ave(bc_df_match$bc_counts, bc_df_match$barcode, FUN = function(x) sum(x))
bc_df_nomatch <- bc_df_nomatch %>% select(barcode, bc_sum) %>% unique()
bc_df_match <- bc_df_match %>% select(barcode, bc_sum) %>% unique()
bc_df_nomatch$mean_coverage <- bc_df_nomatch$bc_sum / 22
bc_df_match$mean_coverage <- bc_df_match$bc_sum / 22

ggplot(data = bc_df_nomatch, aes(x = mean_coverage)) + 
  geom_density() + xlab("mean coverage") + 
  xlim(1,100) +
  labs(title = "barcode reads - unmatched barcodes") +
  theme_classic()

ggplot(data = bc_df_match, aes(x = mean_coverage)) + 
  geom_density() + xlab("mean coverage") + 
  xlim(1,100) +
  labs(title = "barcode reads - matched barcodes") +
  theme_classic()


## How many barcodes are unmatched?
n_match <- nrow(bc_df_match)
n_nomatch <- nrow(bc_df_nomatch)

# Create donut chart
data <- data.frame(
  lbls=c("matched:", "unmatched:"),
  count=c(n_match, n_nomatch)
)
 
# Compute percentages
data$fraction <- data$count / sum(data$count)
data$percentage <- data$fraction * 100


# Compute the cumulative percentages (top of each rectangle)
data$ymax <- cumsum(data$fraction)


# Compute the cumulative percentages (top of each rectangle)
data$ymax <- cumsum(data$fraction)

# Compute the bottom of each rectangle
data$ymin <- c(0, head(data$ymax, n=-1))

# Compute label position
data$labelPosition <- (data$ymax + data$ymin) / 2

# Compute a good label
data$label <- paste0(data$lbls, "\n", round(data$percentage), "%")

# Make the plot
ggplot(data, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=lbls)) +
  geom_rect() +
  geom_text(x=2, aes(y=labelPosition, label=label, color=lbls), size=5) + # x here controls label position (inner / outer)
  scale_fill_manual(values = c("#1B998B", "#2D3047")) +
  scale_color_manual(values = c("#1B998B", "#2D3047")) +
  labs(title = "percentage of barcodes matched") +
  coord_polar(theta="y") +
  xlim(c(0, 4)) +
  theme_void() +
  theme(legend.position = "none")



## How many reads do I loose through match filtering?
n_match_reads <- sum(bc_df_match$bc_sum)
n_nomatch_reads <- sum(bc_df_nomatch$bc_sum)

# Create donut chart
data <- data.frame(
  lbls=c("matched:", "unmatched:"),
  count=c(n_match_reads, n_nomatch_reads)
)
 
# Compute percentages
data$fraction <- data$count / sum(data$count)
data$percentage <- data$fraction * 100


# Compute the cumulative percentages (top of each rectangle)
data$ymax <- cumsum(data$fraction)


# Compute the cumulative percentages (top of each rectangle)
data$ymax <- cumsum(data$fraction)

# Compute the bottom of each rectangle
data$ymin <- c(0, head(data$ymax, n=-1))

# Compute label position
data$labelPosition <- (data$ymax + data$ymin) / 2

# Compute a good label
data$label <- paste0(data$lbls, "\n", round(data$percentage), "%")

# Make the plot
ggplot(data, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=lbls)) +
  geom_rect() +
  geom_text(x=2, aes(y=labelPosition, label=label, color=lbls), size=5) + # x here controls label position (inner / outer)
  scale_fill_manual(values = c("#1B998B", "#2D3047")) +
  scale_color_manual(values = c("#1B998B", "#2D3047")) +
  labs(title = "percentage of barcodes matched") +
  coord_polar(theta="y") +
  xlim(c(0, 4)) +
  theme_void() +
  theme(legend.position = "none")


# Remove unmatched barcodes (as they only have a few reads)
bc_df <- bc_df[!is.na(bc_df$seq),]
```



## Inspect pDNA counts to characterize the transfected library
```{r pDNA inspection, out.width= "100%", fig.align= "center", echo=FALSE, warning= FALSE}
## Correltaion pDNA 1 & 2
pDNA <- bc_df %>% select(pDNA_1, pDNA_2, barcode)

sp <- ggscatter(pDNA, x = "pDNA_1", y = "pDNA_2",
   add = "reg.line", 
   add.params = list(color = "blue", fill = "lightgray"),
   conf.int = TRUE, ylab = "Barcode counts - Replicate 2", xlab = "Barcode counts - Replicate 1",
   title = "Correlation between replicates - barcode counts in pDNA",
   xlim = c(0, 6000), ylim = c(0,6000))
sp + stat_cor(method = "pearson", label.x = 3, label.y = 6000) + geom_abline(linetype = "dashed")



# pDNA density
bc_df$pDNA <- rowMeans(bc_df %>% select(pDNA_1, pDNA_2))
pDNA <- bc_df %>% select(barcode, pDNA)



## How many barcodes do I loose through pDNA filtering?
pDNA_0 <- nrow(pDNA[pDNA$pDNA < 100,])
pDNA_1 <- nrow(pDNA[pDNA$pDNA >= 100,])



# Create donut chart
data <- data.frame(
  lbls=c("kept", "lost"),
  count=c(pDNA_1, pDNA_0)
)
 
# Compute percentages
data$fraction <- data$count / sum(data$count)
data$percentage <- data$fraction * 100


# Compute the cumulative percentages (top of each rectangle)
data$ymax <- cumsum(data$fraction)


# Compute the cumulative percentages (top of each rectangle)
data$ymax <- cumsum(data$fraction)

# Compute the bottom of each rectangle
data$ymin <- c(0, head(data$ymax, n=-1))

# Compute label position
data$labelPosition <- (data$ymax + data$ymin) / 2

# Compute a good label
data$label <- paste0(data$lbls, "\n", round(data$percentage), "%")

# Make the plot
ggplot(data, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=lbls)) +
  geom_rect() +
  geom_text(x=2, aes(y=labelPosition, label=label, color=lbls), size=5) + # x here controls label position (inner / outer)
  scale_fill_manual(values = c("#1B998B", "#2D3047")) +
  scale_color_manual(values = c("#1B998B", "#2D3047")) +
  labs(title = "pDNA reads lost through filtering") +
  coord_polar(theta="y") +
  xlim(c(0, 4)) +
  theme_void() +
  theme(legend.position = "none")






## How many cDNA reads do I loose through pDNA filtering?
cDNA <- bc_df[bc_df$pDNA < 100,]
cDNA <- cDNA %>% select(-length, -TF, -spacing, -distance, -`bc.number`, -promoter, -background, -seq,
                        -pDNA_1, -pDNA_2)
cDNA <- melt(cDNA, id.vars = c("barcode"), variable.name = "condition", value.name = "bc_counts")
cDNA <- sum(cDNA$bc_counts)

cDNA_1 <- bc_df[bc_df$pDNA >= 100,]
cDNA_1 <- cDNA_1 %>% select(-length, -TF, -spacing, -distance, -`bc.number`, -promoter, -background, -seq,
                        -pDNA_1, -pDNA_2)
cDNA_1 <- melt(cDNA_1, id.vars = c("barcode"), variable.name = "condition", value.name = "bc_counts")
cDNA_1 <- sum(cDNA_1$bc_counts)


# Create donut chart
data <- data.frame(
  lbls=c("kept", "lost"),
  count=c(cDNA_1, cDNA)
)
 
# Compute percentages
data$fraction <- data$count / sum(data$count)
data$percentage <- data$fraction * 100


# Compute the cumulative percentages (top of each rectangle)
data$ymax <- cumsum(data$fraction)


# Compute the cumulative percentages (top of each rectangle)
data$ymax <- cumsum(data$fraction)

# Compute the bottom of each rectangle
data$ymin <- c(0, head(data$ymax, n=-1))

# Compute label position
data$labelPosition <- (data$ymax + data$ymin) / 2

# Compute a good label
data$label <- paste0(data$lbls, "\n", round(data$percentage), "%")

# Make the plot
ggplot(data, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=lbls)) +
  geom_rect() +
  geom_text(x=2, aes(y=labelPosition, label=label, color=lbls), size=5) + # x here controls label position (inner / outer)
  scale_fill_manual(values = c("#1B998B", "#2D3047")) +
  scale_color_manual(values = c("#1B998B", "#2D3047")) +
  labs(title = "pDNA reads lost through filtering") +
  coord_polar(theta="y") +
  xlim(c(0, 4)) +
  theme_void() +
  theme(legend.position = "none")


ggplot(data = pDNA, aes(x = "pDNA counts per barcode", y = pDNA)) + 
  geom_quasirandom(color = "#2D3047") + 
  labs(title = "pDNA barcode count distribution") +
  theme_classic() + geom_hline(yintercept = 100, linetype = "dashed", color = "#1B998B", size = 1.5) +
  theme(axis.text.x = element_text(size = 12), 
          axis.text.y = element_text(size = 12)) +
  ylab("") + xlab("") +
  theme(text = element_text(size = 12))



# Which samples are not represented in pDNA?
## Check if there's a specific TF
pDNA <- bc_df %>% select(pDNA_1, pDNA_2, barcode, TF) 
pDNA$pDNA <- rowMeans(pDNA %>% select(pDNA_1, pDNA_2)) 
pDNA <- pDNA %>% select(barcode, pDNA, TF)
TF_count <- data.frame(table(pDNA$TF))
names(TF_count) <- c("TF", "TF_count")
pDNA <- merge(pDNA, TF_count, all = T)
for (i in unique(pDNA$TF)) {
  pDNA_count <- pDNA[pDNA$TF == i,]
  pDNA$nonzerocount[pDNA$TF == i] <- length(pDNA_count$TF[pDNA_count$pDNA < 100])
}
pDNA$fraction <- pDNA$nonzerocount / pDNA$TF_count
pDNA_TF <- pDNA %>% select(TF, fraction) %>% unique()
pDNA_TF$mean <- mean(pDNA_TF$fraction)

ggplot(data = pDNA_TF, aes(x = reorder(TF, -fraction), y = fraction)) + 
  geom_bar(stat = "identity") + xlab("TF") + ylab("Fraction reporters without pDNA counts") + 
  labs(title = "Barcode counts vs. TF reporter length") + 
  geom_line(aes(y = mean, group = mean), linetype = "dashed") +
  theme_classic() + theme(axis.text.x = element_text(angle = 90, hjust = 1.0, vjust = 0))


# Are there any samples from which I don'y have any barcode?
## Make a #barcode coverage per sample density plot
pDNA_bc <- bc_df %>% select(pDNA_1, pDNA_2, barcode, length, TF, spacing,
                            distance, `bc.number`, promoter, background)
pDNA_bc$pDNA <- rowMeans(pDNA_bc %>% select(pDNA_1, pDNA_2))
pDNA_bc$id <- paste(pDNA_bc$TF, pDNA_bc$spacing, pDNA_bc$distance, pDNA_bc$promoter, pDNA_bc$background)
pDNA_bc <- pDNA_bc %>% select(id, pDNA, `bc.number`)
for (i in unique(pDNA_bc$id)) {
  pDNA_count <- pDNA_bc[pDNA_bc$id == i,]
  pDNA_bc$nonzerocount[pDNA_bc$id == i] <- length(pDNA_count$id[pDNA_count$pDNA >= 100])
}
pDNA_bc <- pDNA_bc %>% select(id, nonzerocount) %>% unique()
pDNA_bc <- pDNA_bc[-grep("hPGK", pDNA_bc$id),]

data <- data.frame(
  lbls=c("8", "7", "6", "5", "4", "3", "2", "1", "0"),
  count=c(nrow(pDNA_bc[pDNA_bc$nonzerocount == 8,]),
          nrow(pDNA_bc[pDNA_bc$nonzerocount == 7,]),
          nrow(pDNA_bc[pDNA_bc$nonzerocount == 6,]),
          nrow(pDNA_bc[pDNA_bc$nonzerocount == 5,]),
          nrow(pDNA_bc[pDNA_bc$nonzerocount == 4,]),
          nrow(pDNA_bc[pDNA_bc$nonzerocount == 3,]),
          nrow(pDNA_bc[pDNA_bc$nonzerocount == 2,]),
          nrow(pDNA_bc[pDNA_bc$nonzerocount == 1,]),
          nrow(pDNA_bc[pDNA_bc$nonzerocount == 0,]))
)

# Compute percentages
data$fraction <- data$count / sum(data$count)
data$percentage <- data$fraction * 100


# Compute the cumulative percentages (top of each rectangle)
data$ymax <- cumsum(data$fraction)


# Compute the cumulative percentages (top of each rectangle)
data$ymax <- cumsum(data$fraction)

# Compute the bottom of each rectangle
data$ymin <- c(0, head(data$ymax, n=-1))

# Compute label position
data$labelPosition <- (data$ymax + data$ymin) / 2

# Compute a good label
data$label <- paste0(data$lbls, "\n", round(data$percentage), "%")

# Make the plot
ggplot(data, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=lbls)) +
  geom_rect() +
  geom_text(x=2, aes(y=labelPosition, label=label), size=4) + # x here controls label position (inner / outer)
  scale_fill_brewer(palette = "Blues") +
  labs(title = "barcodes per reporter") +
  coord_polar(theta="y") +
  xlim(c(0, 4)) +
  theme_void() +
  theme(legend.position = "none")

# Use long data to see pDNA count vs TF reporter length distribution
bc_df_long <- melt(bc_df, id.vars = c("barcode","TF", "spacing", "distance", "bc.number", 
                                 "promoter", "background", "seq", "length"), 
              variable.name = "condition", value.name = "bc_counts")

# Distribute lengths in bins
lengths <- seq(140,250,10)
bc_df_long$length_bin <- cut(bc_df_long$length, breaks = lengths)

## Read distribution vs. TF reporter length
ggplot(data = bc_df_long[grep("pDNA", bc_df_long$condition),], aes(x = length_bin, y = `bc_counts`)) + 
  geom_quasirandom(color = "#2D3047") + xlab("TF reporter length") + 
  labs(title = "Barcode counts vs. TF reporter length") + 
  theme_classic() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1, size = 12), 
          axis.text.y = element_text(size = 12)) +
  ylab("Barcode counts") + 
  geom_hline(yintercept = 100, linetype = "dashed", color = "#1B998B", size = 1) +
  theme(text = element_text(size = 12))


## Check if low pDNA counts happens in some length bins more often
pDNA <- bc_df_long[grep("pDNA", bc_df_long$condition),]
pDNA_0 <- pDNA[pDNA$bc_counts < 100,]

ggplot(data = pDNA, aes(x = length)) + 
  geom_density(fill ="#AAACB0", alpha = 0.5) + geom_density(data = pDNA_0, fill ="#BFEDC1", alpha = 0.5) +
  xlab("TF reporter length") + labs(title = "Length distribution of TF reporters", subtitle = "green: >100 pDNA counts, grey: >= 100 pDNA counts") + 
  theme_classic()


# Remove all barcodes that did not appear in pDNA data
bc_df[is.na(bc_df)] <- 0
bc_df <- bc_df[bc_df$pDNA >= 100,]

# Data distribution after filtering
pDNA <- bc_df %>% select(pDNA)
ggplot(data = pDNA, aes(x = pDNA)) + 
  geom_density() + xlab("barcode counts") + labs(title = "pDNA barcode count distribution") +
  theme_classic()
ggplot(data = pDNA, aes(x = pDNA)) + 
  geom_density() + xlab("barcode counts") + labs(title = "pDNA barcode count distribution") +
  xlim(0,1000) + theme_classic()
```



## Restructure df
```{r out.width= "100%", fig.align= "center", echo=FALSE, warning= FALSE}
# Wide to long 
bc_df <- melt(bc_df, id.vars = c("barcode","TF", "spacing", "distance", "bc.number", 
                                 "promoter", "background", "seq", "length"), 
              variable.name = "condition", value.name = "bc_counts")
bc_df <- bc_df[bc_df$condition != "pDNA",]
# Include replicates
bc_df$rep <- gsub(".*([1-3]$)", "\\1", bc_df$condition)
```


## Data quality plots - total reads
```{r read count 3, out.width= "100%", fig.align= "center", echo=FALSE, warning= FALSE}
## Mean read counts each experiment
bc_df$mean_counts <- ave(bc_df$bc_counts, bc_df$condition, FUN = function(x) mean(x))
bc_df_mean <- bc_df %>% select(mean_counts, condition) %>% unique()
bc_df_mean$total_mean <- mean(bc_df_mean$mean_counts)

p <- ggplot(data = bc_df_mean, aes(y = mean_counts, x = reorder(condition, -mean_counts))) + 
  geom_bar(stat = "identity") + xlab("Experimental condition") + ylab("Mean read counts TF reporter") +
  labs(title = "Mean barcode coverage per condition", 
       subtitle = paste("Mean coverage: ", round(bc_df_mean$total_mean,2), "x", sep = "")) + 
  theme_classic() + theme(axis.text.x = element_text(angle = 90, hjust = 1.0, vjust = 0)) 


p + geom_line(aes(y = total_mean, group = total_mean), linetype = "dashed")
```







## Normalization of barcode counts in two steps:
1. Divide barcode counts through sequencing depth - I assume that sequencing depth is not skewed by differential reporter activity
2. Divide cDNA barcode counts through pDNA barcode counts to get activity
```{r normalization, out.width= "100%", fig.align= "center", echo=FALSE, warning= FALSE}
# Normalize data using pDNA data

## First normalize barcode counts to sequencing depth (rpm)
for (i in unique(bc_df$condition)) {
  lib_size <- sum(bc_df$bc_counts[bc_df$condition == i]) / 1e6
  bc_df$bc_counts_rpm[bc_df$condition == i]<- bc_df$bc_counts[bc_df$condition == i] / lib_size
}


## Compute activity by dividing through pDNA data
 n <- 0
 for (i in unique(bc_df$barcode)) {
    # Compute mean of bc count of rpm_pDNA data for each barcode 
    pDNA_1 <- bc_df$bc_counts_rpm[bc_df$barcode == i & bc_df$condition == "pDNA_1"]
    pDNA_2 <- bc_df$bc_counts_rpm[bc_df$barcode == i & bc_df$condition == "pDNA_2"] 
    c <- c(pDNA_1, pDNA_2)
    pDNA <- mean(c)
  
    # cDNA data for each barcode
    cDNA <- bc_df$bc_counts_rpm[bc_df$barcode == i]
  
    # Compute activity by dividing cDNA rpm data by mean pDNA rpm data 
    bc_df$activity[bc_df$barcode == i] <- cDNA / pDNA
    
    # Keep track of the progress
    n <- n + length(i)
    percent <- round((n / length(unique(bc_df$barcode)))*100,2)
    progress <- paste("progress:", percent, "%")
    if (percent %% 1 == 0) {
    print(progress)
  }
}

bc_df$activity[is.na(bc_df$activity)] <- 0
```







## Calculate mean activity - filter out outlier barcodes 
```{r out.width= "100%", fig.align= "center", echo=FALSE, warning= FALSE}
# First identify and remove outlier barcodes - this removes the noise created by faulty barcode clustering etc. 
## Calculate mean and SD for each reporter
bc_df_cDNA <- bc_df[-grep("pDNA", bc_df$condition),]
bc_df_cDNA$reporter_id <- paste(bc_df_cDNA$TF, bc_df_cDNA$spacing, 
                                bc_df_cDNA$distance, bc_df_cDNA$promoter,
                                bc_df_cDNA$background, sep = "_")
bc_df_cDNA$mean_activity <- ave(bc_df_cDNA$activity, bc_df_cDNA$reporter_id, 
                                bc_df_cDNA$condition, FUN =
                                  function(x) mean(x))
bc_df_cDNA$sd_activity <- ave(bc_df_cDNA$activity, bc_df_cDNA$reporter_id, 
                              bc_df_cDNA$condition,  FUN =
                                  function(x) sd(x))

## Remove data points that are 2xSD away from the mean
bc_df_cDNA$upper_activity <- bc_df_cDNA$mean_activity + (2 * bc_df_cDNA$sd_activity)
bc_df_cDNA$lower_activity <- bc_df_cDNA$mean_activity - (2 * bc_df_cDNA$sd_activity)

bc_df_cDNA$low_outlier <- bc_df_cDNA$activity - bc_df_cDNA$lower_activity
bc_df_cDNA$high_outlier <- bc_df_cDNA$upper_activity - bc_df_cDNA$activity

## Choose arbitrary cutoff to get rid of most extreme outliers
bc_df_cDNA_filt <- bc_df_cDNA[bc_df_cDNA$low_outlier > -0.5 & bc_df_cDNA$high_outlier > -2,]

## Recalculate mean and sd
bc_df_cDNA_filt$mean_activity <- ave(bc_df_cDNA_filt$activity, bc_df_cDNA_filt$reporter_id, 
                                bc_df_cDNA_filt$condition, FUN =
                                  function(x) mean(x))
bc_df_cDNA_filt$sd_activity <- ave(bc_df_cDNA_filt$activity, bc_df_cDNA_filt$reporter_id, 
                              bc_df_cDNA_filt$condition,  FUN =
                                  function(x) sd(x))
```


## Add pDNA data
```{r}
pDNA <- bc_df[grep("pDNA", bc_df$condition),] %>% 
  select(barcode, bc_counts_rpm) %>% unique() %>%
  setnames("bc_counts_rpm", "pDNA_counts_rpm") %>%
  mutate(pDNA_counts_rpm = ave(pDNA_counts_rpm, barcode, FUN = function(x) mean(x))) %>%
  unique()
bc_df_cDNA_filt <- merge(pDNA, bc_df_cDNA_filt, all = T)
bc_df_cDNA_filt <- bc_df_cDNA_filt[!is.na(bc_df_cDNA_filt$condition),]
```




## Annotate controls
```{r out.width= "100%", fig.align= "center", echo=FALSE, warning= FALSE}
# Annotate the mutated motif of each TF
bc_df_cDNA_filt$neg_ctrls <- "No"
bc_df_cDNA_filt$neg_ctrls[grep("neg", bc_df_cDNA_filt$TF)] <- "Yes"

# Annotate hPGK postive control
bc_df_cDNA_filt$hPGK <- "No"
bc_df_cDNA_filt$hPGK[grep("hPGK", bc_df_cDNA_filt$TF)] <- "Yes"

# Annotate enhancer controls
bc_df_cDNA_filt$native_enhancer <- "No"
bc_df_cDNA_filt$native_enhancer[grep("klf2", bc_df_cDNA_filt$TF)] <- "Yes"

# Annotate random promoter control
bc_df_cDNA_filt$rand_promoter <- "No"
bc_df_cDNA_filt$rand_promoter[grep("Random", bc_df_cDNA_filt$promoter)] <- "Yes"

bc_df_cDNA_filt <- bc_df_cDNA_filt[!is.na(bc_df_cDNA_filt$condition),] 
```




## Recalculate correlations
```{r correlations_2, out.width= "100%", fig.align= "center", echo=FALSE, warning= FALSE}
## Combine replicates in 8 different columns
bc_df_rep <- bc_df_cDNA_filt[bc_df_cDNA_filt$hPGK == "No" & bc_df_cDNA_filt$native_enhancer == "No" &
                          bc_df_cDNA_filt$rand_promoter == "No",] %>% 
  select(`bc.number`, activity, condition, reporter_id)
rep1 <- bc_df_rep[bc_df_rep$`bc.number` == 1,] %>% select(-`bc.number`)
rep2 <- bc_df_rep[bc_df_rep$`bc.number` == 2,] %>% select(-`bc.number`)
rep3 <- bc_df_rep[bc_df_rep$`bc.number` == 3,] %>% select(-`bc.number`)
rep4 <- bc_df_rep[bc_df_rep$`bc.number` == 4,] %>% select(-`bc.number`)
rep5 <- bc_df_rep[bc_df_rep$`bc.number` == 5,] %>% select(-`bc.number`)
rep6 <- bc_df_rep[bc_df_rep$`bc.number` == 6,] %>% select(-`bc.number`)
rep7 <- bc_df_rep[bc_df_rep$`bc.number` == 7,] %>% select(-`bc.number`)
rep8 <- bc_df_rep[bc_df_rep$`bc.number` == 8,] %>% select(-`bc.number`)

setnames(rep1, "activity", "bc1")
setnames(rep2, "activity", "bc2")
setnames(rep3, "activity", "bc3")
setnames(rep4, "activity", "bc4")
setnames(rep5, "activity", "bc5")
setnames(rep6, "activity", "bc6")
setnames(rep7, "activity", "bc7")
setnames(rep8, "activity", "bc8")

bc_df_rep <- merge(rep1, rep2, all = T)
bc_df_rep <- bc_df_rep[rowSums(is.na(bc_df_rep)) != ncol(bc_df_rep), ]
bc_df_rep <- merge(bc_df_rep, rep3, all = T)
bc_df_rep <- merge(bc_df_rep, rep4, all = T)
bc_df_rep <- bc_df_rep[rowSums(is.na(bc_df_rep)) != ncol(bc_df_rep), ]
bc_df_rep <- merge(bc_df_rep, rep5, all = T)
bc_df_rep <- merge(bc_df_rep, rep6, all = T)
bc_df_rep <- bc_df_rep[rowSums(is.na(bc_df_rep)) != ncol(bc_df_rep), ]
bc_df_rep <- merge(bc_df_rep, rep7, all = T)
bc_df_rep <- merge(bc_df_rep, rep8, all = T)
bc_df_rep <- bc_df_rep[rowSums(is.na(bc_df_rep)) != ncol(bc_df_rep), ]


# Correlation matrix plot
n <- sample(1:nrow(bc_df_rep), 5000)
boundaries <- seq(from = 0.8, by = 0.05, length.out = 4)
plt <- ggpairs(bc_df_rep %>% select(bc1, bc2, bc3, bc4, bc5, bc6, bc7, bc8),
               upper = list(continuous = corColor),
               lower = list(continuous = function(data, mapping, ...) {
                   ggally_points(data = data[n, ], mapping = mapping, alpha = 0.1, size = 0.5) +
                   geom_abline(slope = 1, lty = "dashed", col = "red") +
                   theme_bw()}),
               diag = list(continuous = function(data, mapping, ...) {
                   ggally_densityDiag(data = data, mapping = mapping, alpha = 0.3, fill = "red") +
                   theme_bw()})) +
  ggtitle("Correlation Between Technial Replicates") +
  theme(text = element_text(size = 20)) +
  xlab("Reporter activity") +
  ylab("Reporter activity") + 
  theme_light()

print(plt)
```



## Data quality plots - correlation between replicates
```{r correlations_3, out.width= "100%", fig.align= "center", echo=FALSE, warning= FALSE}
# Correlation plots of the replicates
## Combine replicates of normalized data in 3 different columns
bc_df_rep <- bc_df_cDNA_filt %>% select(rep, mean_activity, reporter_id, condition) %>% unique()
bc_df_rep$condition <- gsub("(.*?)_r[1-3]$", "\\1", bc_df_rep$condition)
rep1 <- bc_df_rep[bc_df_rep$rep == 1,]
rep2 <- bc_df_rep[bc_df_rep$rep == 2,]
rep3 <- bc_df_rep[bc_df_rep$rep == 3,]
rep1 <- rep1 %>% select(-rep)
rep2 <- rep2 %>% select(-rep)
rep3 <- rep3 %>% select(-rep)

names(rep1) <- c("rep1", "reporter", "condition")
names(rep2) <- c("rep2", "reporter", "condition")
names(rep3) <- c("rep3", "reporter", "condition")

bc_df_rep <- merge(rep1, rep2, all = TRUE)
bc_df_rep <- merge(bc_df_rep, rep3, all = TRUE)
bc_df_rep$neg_ctrl <- "No"
bc_df_rep$neg_ctrl[grep("neg", bc_df_rep$reporter)] <- "Yes"

colors <- c("#2D3047", "#1B998B")

sp1 <- ggscatter(bc_df_rep, x = "rep1", y = "rep2",
   add = "reg.line",
   color = "neg_ctrl",
   size = 1,
   add.params = list(color = "blue", fill = "lightgray"), title = "rep1 vs rep2",
   conf.int = TRUE, ylab = "rep2", xlab = "rep1") + 
  stat_cor(method = "pearson", label.x = 1, label.y = 25) + 
  geom_abline(linetype = "dashed") +
  scale_color_manual(values = colors)

sp2 <- ggscatter(bc_df_rep, x = "rep1", y = "rep3",
   add = "reg.line",
   color = "neg_ctrl",
   size = 1,
   add.params = list(color = "blue", fill = "lightgray"), title = "rep1 vs rep3",
   conf.int = TRUE, ylab = "rep3", xlab = "rep1") + 
  stat_cor(method = "pearson", label.x = 1, label.y = 25) + 
  geom_abline(linetype = "dashed")+
  scale_color_manual(values = colors)

sp3 <- ggscatter(bc_df_rep, x = "rep3", y = "rep2",
   add = "reg.line",
   color = "neg_ctrl",
   size = 1,
   add.params = list(color = "blue", fill = "lightgray"), title = "rep3 vs rep2",
   conf.int = TRUE, ylab = "rep2", xlab = "rep3") + 
  stat_cor(method = "pearson", label.x = 1, label.y = 25) + 
  geom_abline(linetype = "dashed")+
  scale_color_manual(values = colors)


#Grid three plots to one panel
sp.plot <- arrangeGrob(sp1,sp2,sp3, nrow = 2, ncol = 2)
grid.arrange(sp.plot)
```



## Summarize replicates: summmarize activity values between biological replicates by their geometric mean
```{r out.width= "100%", fig.align= "center", echo=FALSE, warning= FALSE}
# Mean of the three replicates
bc_df_cDNA_filt$condition <- gsub("(.*?)_r[1-3]$", "\\1", bc_df_cDNA_filt$condition)
bc_df_cDNA_filt$reporter_activity <- ave(bc_df_cDNA_filt$activity, bc_df_cDNA_filt$reporter_id, bc_df_cDNA_filt$condition, FUN = function(x) mean(x))
bc_df_cDNA_filt$reporter_activity_sd <- ave(bc_df_cDNA_filt$activity, bc_df_cDNA_filt$reporter_id, bc_df_cDNA_filt$condition, FUN = function(x) sd(x))
```


## Exporting data
```{r data export, out.width= "100%", fig.align= "center", echo=FALSE, warning= FALSE}
# Polish export dataframe
bc_df_cDNA_filt <- bc_df_cDNA_filt %>% 
  select(-upper_activity, -lower_activity, 
         -high_outlier, -low_outlier,) %>% 
  setnames(old = c("mean_activity", "sd_activity"), 
           new = c("replicate_activity", "replicate_activity_sd")) %>% 
  mutate(log_activity = log2(activity),
         log_reporter_activity = log2(reporter_activity))
bc_df_cDNA_filt$condition <- gsub("^X", "", bc_df_cDNA_filt$condition)


# Export bc_df for cDNA analysis
filename <- SetFileName("_reporter_activity_filt", "mt")
setwd("/DATA/usr/m.trauernicht/projects/tf_activity_reporter/data/SuRE_TF_1/results/")
write.csv(bc_df_cDNA_filt, file = paste(filename,".csv", sep = ""), row.names = F)
```

# Session Info
```{r}
paste("Run time: ",format(Sys.time()-StartTime))
getwd()
date()
sessionInfo()
```

