---
title: "Barcode processing"
author: "Max Trauernicht"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output: 
  prettydoc::html_pretty:
    theme: leonids
    highlight: github
  #   toc: true
  #   toc_float: true
  #   code_folding: show
  # editor_options:
  #   chunk_output_type: console
---

*knitr document van Steensel lab*

# TF reporter barcode processing

## Introduction
18,000 TF reporters on pMT02 were transfected into mESCs and NPCs (in total 7 different conditions), sequencing data yielded barcode counts of these experiments. These counts will be processed in this script. 


```{r setup, out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
StartTime <-Sys.time()

# 8-digit Date tag:
Date <- substr(gsub("-","",Sys.time()),1,8) 
# libraries:
library(data.table)
library(plyr)
library(stringr)
library(ggpubr)
library(GGally)
library(vwr)
library(dplyr)
library(tibble)
library(plotly)
library(ggbeeswarm)
library(haven)
library(readr)
library(parallel)
library(RColorBrewer)
library(gridExtra)
library(LncFinder)
```


```{r out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE, message=FALSE}
# Custom functions
SetFileName <- function(filename, initials) {
  # Set filename with extension and initials to make filename with date integrated.
  filename <- substitute(filename)
  initials <- substitute(initials)
  filename <- paste0(initials, Date, filename)
  filename
}

ReadFasta<-function(file) {
   # Read the file line by line
   fasta<-readLines(file)
   # Identify header lines
   ind<-grep(">", fasta)
   # Identify the sequence lines
   s<-data.frame(ind=ind, from=ind+1, to=c((ind-1)[-1], length(fasta)))
   # Process sequence lines
   seqs<-rep(NA, length(ind))
   for(i in 1:length(ind)) {
      seqs[i]<-paste(fasta[s$from[i]:s$to[i]], collapse="")
   }
   # Create a data frame 
   DF<-data.frame(name=gsub(">", "", fasta[ind]), sequence=seqs)
   # Return the data frame as a result object from the function
   return(DF)
}

# From Fede:
# ggpairs custom functions
corColor <- function(data, mapping, color = I("black"), sizeRange = c(1, 3), ...) {

  x   <- eval_data_col(data, mapping$x)
  y   <- eval_data_col(data, mapping$y)
  r   <- cor(x, y, "pairwise.complete.obs")
  rt  <- format(r, digits = 3)
  tt  <- as.character(rt)
  cex <- max(sizeRange)

  # helper function to calculate a useable size
  percent_of_range <- function(percent, range) {
    percent * diff(range) + min(range, na.rm = TRUE)
  }

  # plot correlation coefficient
  p <- ggally_text(label = tt, mapping = aes(), xP = 0.5, yP = 0.5,
                   size = I(percent_of_range(cex * abs(r), sizeRange)), color = color, ...) +
    theme(panel.grid.minor=element_blank(),
          panel.grid.major=element_blank())

  corColors <- RColorBrewer::brewer.pal(n = 7, name = "RdYlBu")[2:6]

  if (r <= boundaries[1]) {
    corCol <- corColors[1]
  } else if (r <= boundaries[2]) {
    corCol <- corColors[2]
  } else if (r < boundaries[3]) {
    corCol <- corColors[3]
  } else if (r < boundaries[4]) {
    corCol <- corColors[4]
  } else {
    corCol <- corColors[5]
  }

  p <- p +
    theme(panel.background = element_rect(fill = corCol))

  return(p)
}
```


```{r data import, out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE, message=FALSE}
# Import barcode counts per experiment
bc_files = list.files('/DATA/usr/m.trauernicht/projects/SuRE-TF/data/gcf5927_stimulation-1/results_e3_s1/',
                       full.names=T, patter='*_barcode_counts.tsv')
bc_list <- lapply(bc_files, fread, header = FALSE)
names(bc_list)<- gsub('.*//(.*?)_[CGAT]{8}.*_barcode_counts.tsv', 
                                    '\\1', 
                                    bc_files)

# Import barcode annotation
bc_annotation <- read.csv("/DATA/usr/m.trauernicht/projects/SuRE-TF/data/library_design/output/mt20191218_tf-array.csv", header = T)
bc_annotation$TF <- as.character(bc_annotation$TF) 
bc_annotation$TF[bc_annotation$TF == "ctrl"] <- "hPGK"

# Manually check clustering 
x <- read_table("/DATA/usr/m.trauernicht/projects/SuRE-TF/data/gcf5927_stimulation-1/bartender/bc_2i_neg_LIF_r1_CGATGTAT_S98_conv_barcode.txt", col_names = F)
y <- read_csv("/DATA/usr/m.trauernicht/projects/SuRE-TF/data/gcf5927_stimulation-1/bartender/2i_neg_LIF_r1_CGATGTAT_S98_cluster_barcode.csv", col_names = F)

barcodes <- bc_annotation$barcode
```

## Analysis

### Compare bartender with starcode
```{r cluster_compare, out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE, message=FALSE}
# Generate long dfs
for (i in 1:22) {
  if (i == 1) {
  bc_df <- data.frame(bc_list[i])
  bc_df[3] <- names(bc_list[i])
  names(bc_df) <- c("barcode", "count", "name")
  bc_df <- reshape2::dcast(bc_df, barcode ~ name, value.var = "count")
  }
  else {
  bc_df_i <- data.frame(bc_list[i])
  bc_df_i[3] <- names(bc_list[i])
  names(bc_df_i) <- c("barcode", "count", "name")
  bc_df_i <- reshape2::dcast(bc_df_i, barcode ~ name, value.var = "count")
  bc_df <- merge(bc_df, bc_df_i, all = T)
  }
}


# Import starcode data
bartender_files = list.files('/DATA/usr/m.trauernicht/projects/SuRE-TF/data/gcf5927_stimulation-1/bartender/',
                       full.names=T, patter='*_cluster_d3_barcode.csv')
bartender_list <- lapply(bartender_files, fread, header = FALSE)
names(bartender_list)<- gsub('.*//(.*?)_[CGAT]{8}.*_cluster_d3_barcode.csv',
                                    '\\1',
                                    bartender_files)


## Convert lists to data frames and reshape
for (i in 1:22) {
  if (i == 1) {
  bartender_df <- data.frame(bartender_list[i])
  bartender_df <- bartender_df[-1,]
  names(bartender_df) <- c("barcode", "count", "cluster")
  bartender_df$count <- as.numeric(bartender_df$count)
  bartender_df$bc_counts <- ave(bartender_df$count, bartender_df$cluster, FUN = function(x) sum(x))
  bartender_df <- bartender_df %>% group_by(cluster) %>% top_n(1, count)
  bartender_df$name <- names(bartender_list[i])
  bartender_df <- bartender_df[,c(-2,-3)]
  bartender_df <- reshape2::dcast(bartender_df, barcode ~ name, value.var = "bc_counts")
  }
  else {
  bartender_df_i <- data.frame(bartender_list[i])
  bartender_df_i <- bartender_df_i[-1,]
  names(bartender_df_i) <- c("barcode", "count", "cluster")
  bartender_df_i$count <- as.numeric(bartender_df_i$count)
  bartender_df_i$bc_counts <- ave(bartender_df_i$count, bartender_df_i$cluster, FUN = function(x) sum(x))
  bartender_df_i <- bartender_df_i %>% group_by(cluster) %>% top_n(1, count)
  bartender_df_i$name <- names(bartender_list[i])
  bartender_df_i <- bartender_df_i[,c(-2,-3)]
  bartender_df_i <- reshape2::dcast(bartender_df_i, barcode ~ name, value.var = "bc_counts")
  bartender_df <- merge(bartender_df, bartender_df_i, all = T)
  }
}


bc_annotation$seq <- paste(bc_annotation$Primer1_seq, bc_annotation$motif1, bc_annotation$Space1,
                                bc_annotation$motif2,bc_annotation$Space2, bc_annotation$motif3,
                                bc_annotation$Space3, bc_annotation$motif4, bc_annotation$Distance_seq,
                                bc_annotation$Promoter_sequence, bc_annotation$S1_primer,
                                bc_annotation$barcode, bc_annotation$Primer2_seq, sep = "")
bc_annotation <- bc_annotation %>% select(TF, Spacing, Distance, Barcode, Promoter, Background,
                                          barcode, seq)
bc_df <- merge(bc_df, bc_annotation, all = T)
bartender_df <- merge(bartender_df, bc_annotation, all = T)
bc_df <- bc_df[!is.na(bc_df$seq),] %>% select(-TF, -Spacing, -Distance, -Barcode,
                                                                -Promoter, -Background, -seq)
bartender_df <- bartender_df[!is.na(bartender_df$seq),]%>% select(-TF, -Spacing, -Distance, -Barcode,
                                                                -Promoter, -Background, -seq)

bc_df_long <- melt(bc_df, id.vars = "barcode",
              variable.name = "condition", value.name = "starcode_counts")

bartender_long <- melt(bartender_df, id.vars = "barcode",
              variable.name = "condition", value.name = "bartender_counts")

comparison_long <- merge(bc_df_long, bartender_long, all = T)

comparison_long[is.na(comparison_long)] <- 0

sp <- ggscatter(comparison_long, x = "starcode_counts", y = "bartender_counts",
   add = "reg.line",
   add.params = list(color = "blue", fill = "lightgray"), title = "barcode counts starcode vs. bartender",
   conf.int = TRUE, ylab = "barcode counts bartender", xlab = "barcode counts starcode")
sp + stat_cor(method = "pearson", label.x = 3, label.y = 40000) + geom_abline(linetype = "dashed")
```

**Conlusion barcode clustering:**  
- optimal starcode settings: levenshtein distance of 1  
- optimal bartender settings: hamming distance of 2  
- starcode and bartender perform equally well - starcode a bit better  
- next time design barcodes requiring levenshtein distance of 3  


### Add barcode annotation to barcode counts & extract first bc read count information
```{r annotation, out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE, message=FALSE}
# Transform lists to df
## Count barcodes - ignore barcode clustering
# for (i in 1:22) {
#   if (i == 1) {
#   bc_df <- data.frame(bc_list[i])
#   bc_df[2] <- names(bc_list[i])
#   names(bc_df) <- c("barcode", "name")
#   bc_df <- reshape2::dcast(bc_df, barcode ~ name) # This will count the barcodes
#   }
#   else {
#   bc_df_i <- data.frame(bc_list[i])
#   bc_df_i[2] <- names(bc_list[i])
#   names(bc_df_i) <- c("barcode", "name")
#   bc_df_i <- reshape2::dcast(bc_df_i, barcode ~ name)
#   bc_df <- merge(bc_df, bc_df_i, all = T)
#   }
# }




## Convert lists to data frames and reshape
for (i in 1:22) {
  if (i == 1) {
  bc_df <- data.frame(bc_list[i])
  bc_df[3] <- names(bc_list[i])
  names(bc_df) <- c("barcode", "count", "name")
  bc_df <- reshape2::dcast(bc_df, barcode ~ name, value.var = "count")
  }
  else {
  bc_df_i <- data.frame(bc_list[i])
  bc_df_i[3] <- names(bc_list[i])
  names(bc_df_i) <- c("barcode", "count", "name")
  bc_df_i <- reshape2::dcast(bc_df_i, barcode ~ name, value.var = "count")
  bc_df <- merge(bc_df, bc_df_i, all = T)
  }
}

# Match TF reporter to barcode
## Match barcode sequences from sequencing with barcodes from oligo design
bc_df <- merge(bc_df, bc_annotation, all = T)
bc_df$TF[bc_df$TF == "ctrl"] <- as_factor("hPGK")

## Include TF reporter length (correlation with pDNA counts?)
bc_df$length <- nchar(bc_df$seq)



## Make a graph to show total reads per condition
bc_df[,2:23][is.na(bc_df[,2:23])] <- 0
bc_df_new <- bc_df
bc_df_new_match <- bc_df_new[!is.na(bc_df_new$seq),]
bc_df_new_match[,2:23] <- as.numeric(unlist(bc_df_new_match[,2:23]))
experimental_reads <- data.frame(colSums(bc_df_new_match[,c(-1, -24:-31)])) %>% 
  tibble::rownames_to_column()
names(experimental_reads) <- c("experiment", "reads")
experimental_reads$mean <- mean(experimental_reads$reads)

p <- ggplot(data = experimental_reads, aes(y = reads, x = reorder(experiment, -reads))) + 
  geom_bar(stat = "identity") + xlab("Experimental condition") + ylab("Total read counts per experiment") +
  labs(title = "Total barcode reads per condition", 
       subtitle = paste("Mean total reads: ", round(experimental_reads$mean,2), "x", sep = "")) + 
  theme_classic() + theme(axis.text.x = element_text(angle = 90, hjust = 1.0, vjust = 0))

p + geom_line(aes(y = mean, group = mean), linetype = "dashed")

## Mean reads per condition are more informative
experimental_reads_mean <- data.frame(colMeans(bc_df_new_match[,c(-1, -24:-31)])) %>% 
  tibble::rownames_to_column()
names(experimental_reads_mean) <- c("experiment", "reads")
experimental_reads_mean$mean <- mean(experimental_reads_mean$reads)

p <- ggplot(data = experimental_reads_mean, aes(y = reads, x = reorder(experiment, -reads))) + 
  geom_bar(stat = "identity") + xlab("Experimental condition") + ylab("Mean read counts per experiment") +
  labs(title = "Mean barcode reads per condition", 
       subtitle = paste("Mean read count: ", round(experimental_reads_mean$mean,2), "x", sep = "")) + 
  theme_classic() + theme(axis.text.x = element_text(angle = 90, hjust = 1.0, vjust = 0))

p + geom_line(aes(y = mean, group = mean), linetype = "dashed")
```


### Get a closer look at unmatched barcodes 
```{r pie unmatch, out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE, message = FALSE}
# Get plots for filtered fraction
bc_df_long <- melt(bc_df, id.vars = c("barcode","TF", "Spacing", "Distance", "Barcode", 
                                 "Promoter", "Background", "seq", "length"), 
              variable.name = "condition", value.name = "bc_counts")
bc_df_long$bc_counts[is.na(bc_df_long$bc_counts)] <- 0


## Identify the unmapped fraction
bc_df_nomatch <- bc_df_long[is.na(bc_df_long$seq),]
bc_df_match <- bc_df_long[!is.na(bc_df_long$seq),]
bc_df_match$bc_counts <- as.numeric(bc_df_match$bc_counts)
bc_df_nomatch$bc_counts <- as.numeric(bc_df_nomatch$bc_counts)
bc_df_nomatch$bc_sum <- ave(bc_df_nomatch$bc_counts, bc_df_nomatch$barcode, FUN = function(x) sum(x))
bc_df_match$bc_sum <- ave(bc_df_match$bc_counts, bc_df_match$barcode, FUN = function(x) sum(x))
bc_df_nomatch <- bc_df_nomatch %>% select(barcode, bc_sum) %>% unique()
bc_df_match <- bc_df_match %>% select(barcode, bc_sum) %>% unique()
bc_df_nomatch$mean_coverage <- bc_df_nomatch$bc_sum / 22
bc_df_match$mean_coverage <- bc_df_match$bc_sum / 22

ggplot(data = bc_df_nomatch, aes(x = mean_coverage)) + 
  geom_density() + xlab("mean coverage") + 
  xlim(1,100) +
  labs(title = "barcode reads - unmatched barcodes") +
  theme_classic()

ggplot(data = bc_df_match, aes(x = mean_coverage)) + 
  geom_density() + xlab("mean coverage") + 
  xlim(1,100) +
  labs(title = "barcode reads - matched barcodes") +
  theme_classic()



## How many barcodes are unmatched?
n_match <- nrow(bc_df_match)
n_nomatch <- nrow(bc_df_nomatch)

# Create donut chart
data <- data.frame(
  lbls=c("matched:", "unmatched:"),
  count=c(n_match, n_nomatch)
)
 
# Compute percentages
data$fraction <- data$count / sum(data$count)
data$percentage <- data$fraction * 100


# Compute the cumulative percentages (top of each rectangle)
data$ymax <- cumsum(data$fraction)


# Compute the cumulative percentages (top of each rectangle)
data$ymax <- cumsum(data$fraction)

# Compute the bottom of each rectangle
data$ymin <- c(0, head(data$ymax, n=-1))

# Compute label position
data$labelPosition <- (data$ymax + data$ymin) / 2

# Compute a good label
data$label <- paste0(data$lbls, "\n", round(data$percentage), "%")

# Make the plot
ggplot(data, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=lbls)) +
  geom_rect() +
  geom_text(x=2, aes(y=labelPosition, label=label, color=lbls), size=5) + # x here controls label position (inner / outer)
  scale_fill_manual(values = c("#1B998B", "#2D3047")) +
  scale_color_manual(values = c("#1B998B", "#2D3047")) +
  labs(title = "percentage of barcodes matched") +
  coord_polar(theta="y") +
  xlim(c(0, 4)) +
  theme_void() +
  theme(legend.position = "none")




## How many reads are unmatched?
n_match_reads <- sum(bc_df_match$bc_sum)
bc_df_nomatch$bc_sum[is.na(bc_df_nomatch$bc_sum)] <- 0
n_nomatch_reads <- sum(bc_df_nomatch$bc_sum)

# Create donut chart
data <- data.frame(
  lbls=c("matched:", "unmatched:"),
  count=c(n_match_reads, n_nomatch_reads)
)
 
# Compute percentages
data$fraction <- data$count / sum(data$count)
data$percentage <- data$fraction * 100


# Compute the cumulative percentages (top of each rectangle)
data$ymax <- cumsum(data$fraction)


# Compute the cumulative percentages (top of each rectangle)
data$ymax <- cumsum(data$fraction)

# Compute the bottom of each rectangle
data$ymin <- c(0, head(data$ymax, n=-1))

# Compute label position
data$labelPosition <- (data$ymax + data$ymin) / 2

# Compute a good label
data$label <- paste0(data$lbls, "\n", round(data$percentage), "%")

# Make the plot
ggplot(data, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=lbls)) +
  geom_rect() +
  geom_text(x=2, aes(y=labelPosition, label=label, color=lbls), size=5) + # x here controls label position (inner / outer)
  scale_fill_manual(values = c("#1B998B", "#2D3047")) +
  scale_color_manual(values = c("#1B998B", "#2D3047")) +
  labs(title = "percentage of barcode reads matched") +
  coord_polar(theta="y") +
  xlim(c(0, 4)) +
  theme_void() +
  theme(legend.position = "none")
```

### Check if the pDNA-bc count correlates with the barcode count in the pDNA-insert-seq data
```{r out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE, message=FALSE}
pDNA_count <- bc_df %>% select(barcode, pDNA_1, pDNA_2) %>%
  mutate(pDNA = (pDNA_1 + pDNA_2) / 2) %>%
  select(barcode, pDNA) %>% 
  mutate(pDNA = ave(pDNA, FUN = function(x) x/sum(x) *1000000))


ref_seq <- ReadFasta("/DATA/usr/m.trauernicht/projects/SuRE-TF/data/library_design/output/mt20191205_oligo_pool.fasta")
ref_seq$sequence <- gsub("CATCGTCGCATCCAAGAG", "", ref_seq$sequence)
ref_seq$barcode <- gsub(".*([A-Z]{12})$", "\\1", ref_seq$sequence)

# Add gc content info
# Load reference file
ref_seq_2 <- seqinr::read.fasta("/DATA/usr/m.trauernicht/projects/SuRE-TF/data/library_design/output/mt20191205_oligo_pool.fasta")

# Compute gc contents
gc <- compute_GC(ref_seq_2)
gc <- gc %>% rownames_to_column(var = "name")
ref_seq <- merge(gc, ref_seq, by = "name")


pDNA_seq <- read_tsv("/DATA/usr/m.trauernicht/projects/SuRE-TF/data/pDNA_insert_seq/pDNA-seq-starcode.tsv", col_names = c("sequence", "number"))

# Split up in insert and barcode part
## In my case, the barcode should be the last 12 bases of the sequence
pDNA_seq$barcode <- gsub(".*([A-Z]{12})$", "\\1", pDNA_seq$sequence)
pDNA_seq <- pDNA_seq %>% select(barcode, number) %>%
  unique()
pDNA_seq <- pDNA_seq %>% 
  group_by(barcode) %>% summarise(number = sum(number))

pDNA_count <- merge(pDNA_count, ref_seq)
pDNA_count <- merge(pDNA_count, pDNA_seq)
pDNA_count <- pDNA_count %>%
  mutate(number = ave(number, FUN = function(x) x/sum(x) *1000000))
pDNA_count$gc_status <- "high"
pDNA_count$gc_status[pDNA_count$GC.content < 0.46] <- "low"



plot_ly(data = pDNA_count, x = ~pDNA, y = ~number, color = ~gc_status) %>% 
  layout(xaxis = list(title = 'bc-seq bc rpm'),
         yaxis = list(title = 'insert-seq bc rpm'))

```


```{r barcode match, out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE, message = FALSE}
# # Where could these unmatched, highly active barcodes come from?
# # Calculate levenshtein distance from barcodes in design to sequenced non-matched barcodes - ilter non-matched barcodes to only include active ones
# bc_nomatch <- bc_df_nomatch$barcode[bc_df_nomatch$bc_sum > 50]
# bc_match <- bc_annotation$barcode
# 
# # For each barcode in the deisgn, calculate the levenshtein distance to each non-matched barcode
# n <- 0
# for (i in 1:17580) {
#   if (i == 1) {
#     l <- data.frame(levenshtein.distance(bc_match[i], bc_nomatch))
#   }
#   else {
#     l[i] <- levenshtein.distance(bc_match[i], bc_nomatch)
# 
#     # Keep track of the progress
#     n <- n + length(i)
#     percent <- (n / 17580)*100
#     progress <- paste("progress:", percent, "%")
#     if (percent %% 10 == 0) {
#     print(progress)
#     }
#   }
# 
# }
# names(l) <- bc_match
# 
# # Only keep sequences with levenshtein distance of 1
# lev <- l
# lev <- lev[rowSums(lev == 1) == 1,colSums(lev == 1) >= 1]
# 
# 
# # Match barcodes with levenshtein distance of 1
# index <- data.frame(which(lev==1, arr.ind=TRUE))
# index <- tibble::rownames_to_column(index)
# for (i in 1:nrow(index)) {
#   index$colname[i] <- colnames(lev)[index$col[i]]
# }
# index <- index %>% select(rowname, colname)
# names(index) <- c("non_match_barcode", "match_barcode")
# 
# 
# # Calculate correlation of each non-matched barcode to the two matched barcodes -> choose highest correlation bc
# # Correlation between matched and unmatched barcode counts
# match_bc_df <- bc_df[bc_df$barcode %in% index$match_barcode,c(1:23)]
# match_bc_df <- melt(match_bc_df, id.vars = c("barcode"), variable.name = "condition", value.name = "bc_counts")
# names(match_bc_df) <- c("match_barcode", "condition", "match_counts")
# match_bc_df <- merge(match_bc_df, index, all = T)
# match_bc_df <- match_bc_df %>% select(-non_match_barcode)
# 
# non_match_bc_df <- bc_df[bc_df$barcode %in% index$`non_match_barcode`,c(1:23)]
# setnames(non_match_bc_df, old = "barcode", new = "non_match_barcode")
# non_match_bc_df <- merge(non_match_bc_df, index, all = T)
# non_match_bc_df <- non_match_bc_df %>% group_by(match_barcode) %>% mutate(rep = seq_len( n() ) )
# non_match_bc_df <- melt(non_match_bc_df, id.vars = c("non_match_barcode", "rep", "match_barcode"), variable.name = "condition", value.name = "bc_counts")
# cor_bc_reads <- merge(match_bc_df, non_match_bc_df, all = T)
# cor_bc_reads[is.na(cor_bc_reads)] <- 0
# 
# # This method is not sensitive for data with very little counts - remove those
# cor_bc_reads$bc_counts <- as.numeric(cor_bc_reads$bc_counts)
# cor_bc_reads$match_counts <- as.numeric(cor_bc_reads$match_counts)
# cor_bc_reads$sum_counts <- ave(cor_bc_reads$bc_counts, cor_bc_reads$rep, cor_bc_reads$match_barcode,
#                                FUN = function(x) sum(x))
# cor_bc_reads <- cor_bc_reads[cor_bc_reads$sum_counts > 1000,]
# 
# cor_bc_reads$copies <- ave(cor_bc_reads$rep, cor_bc_reads$match_barcode,
#                                FUN = function(x) length(unique(x)))
# 
# cor_bc_reads <- unique(cor_bc_reads)
# 
# # For each barcode compute correlation of matched vs. unmatched rep 1-4
# n <- 0
# 
# for (i in unique(cor_bc_reads$non_match_barcode)) {
#     cor_bc_reads$cor[cor_bc_reads$non_match_barcode == i] <-
#       cor(cor_bc_reads$match_counts[cor_bc_reads$non_match_barcode == i],
#           cor_bc_reads$bc_counts[cor_bc_reads$non_match_barcode == i])
# 
#     n <- n + length(i)
#     percent <- (n / length(unique(cor_bc_reads$non_match_barcode)))*100
#     progress <- paste("progress:", percent, "%")
#     if (percent %% 10 == 0) {
#     print(progress)
#   }
# }
# 
# 
# # Filter out those with a weak correlation - this automatically keeps the correct ones with many counts
# cor_bc_reads[is.na(cor_bc_reads)] <- 0
# cor_bc_reads_low <- cor_bc_reads[cor_bc_reads$cor <= 0.75,]
# cor_bc_reads <- cor_bc_reads[cor_bc_reads$cor > 0.75,]
# cor_bc_reads <- cor_bc_reads %>% select(-condition, -match_counts, -bc_counts)
# cor_bc_reads <- unique(cor_bc_reads)
# 
# 
# 
# # Correlation between matched and unmatched barcode counts
# index_3 <- cor_bc_reads
# match_bc_df <- bc_df[bc_df$barcode %in% index_3$match_barcode,c(1:23)]
# match_bc_df <- melt(match_bc_df, id.vars = c("barcode"), variable.name = "condition", value.name = "bc_counts")
# names(match_bc_df) <- c("match_barcode", "condition", "match_counts")
# match_bc_df <- merge(match_bc_df, index_3, all = T)
# 
# non_match_bc_df <- bc_df[bc_df$barcode %in% index_3$non_match_barcode,c(1:23)]
# non_match_bc_df <- melt(non_match_bc_df, id.vars = c("barcode"), variable.name = "condition", value.name = "bc_counts")
# names(non_match_bc_df) <- c("non_match_barcode", "condition", "non_match_counts")
# non_match_bc_df <- merge(non_match_bc_df, index_3, all = T)
# non_match_bc_df <- non_match_bc_df %>% select(-`non_match_barcode`)
# cor_bc_reads <- merge(match_bc_df, non_match_bc_df, all = T)
# cor_bc_reads[is.na(cor_bc_reads)] <- 0
# 
# sp <- ggscatter(cor_bc_reads, x = "match_counts", y = "non_match_counts",
#    add = "reg.line",
#    add.params = list(color = "blue", fill = "lightgray"), title = "correlation matched vs. unmatched barcodes",
#    conf.int = TRUE, ylab = "bc counts unmatched", xlab = "bc counts matched")
# sp + stat_cor(method = "pearson", label.x = 3, label.y = 6000) + geom_abline(linetype = "dashed")
# 
# 
# 
# cor_bc_reads <- cor_bc_reads %>% select(match_barcode, non_match_barcode) %>% unique()
# 
# 
# # Change barcodes in bc_df to matched barcodes
# n <- 0
# 
# bc_nomatch_low <- bc_df_nomatch$barcode[bc_df_nomatch$bc_sum <= 100]
# bc_df <- subset(bc_df, !(bc_df$barcode %in% bc_nomatch_low))
# 
# for (i in unique(bc_df$barcode)) {
#   if (i %in% cor_bc_reads$non_match_barcode) {
#     k <- which(grepl(i, cor_bc_reads$non_match_barcode))
#     bc_df$barcode[bc_df$barcode == i] <- cor_bc_reads$match_barcode[k]
# 
#     n <- n + length(i)
#     percent <- (n / length(unique(bc_df$barcode))*100)
#     progress <- paste("progress:", percent, "%")
#     if (percent %% 10 == 0) {
#     print(progress)
#     }
#   }
# }
# 
# # Sum up identical barcodes
# bc_df[,2:23][is.na(bc_df[,2:23])] <- 0
# bc_df <- merge(bc_df, bc_annotation, by = "barcode", all = T)
# bc_df <- bc_df %>% select(-TF.x, -Spacing.x, -Distance.x, -Barcode.x, -Promoter.x, -Background.x, -seq.x)
# setnames(bc_df,
#          old = c("TF.y", "Spacing.y", "Distance.y", "Barcode.y", "Promoter.y", "Background.y", "seq.y" ),
#          new = c("TF", "spacing", "distance", "bc-number", "promoter", "background", "seq"))
# bc_df$length <- nchar(bc_df$seq)
# 
# bc_df <- ddply(bc_df,~barcode + length + TF + spacing + distance + `bc-number` + promoter +
#                    background + seq,
#                  summarise, `2i_neg_LIF_r1` = sum(`2i_neg_LIF_r1`),
#             `2i_neg_LIF_r2` = sum(`2i_neg_LIF_r2`),
#             `2i_neg_LIF_r3` = sum(`2i_neg_LIF_r3`),
#             `2i_pos_LIF_r1` = sum(`2i_pos_LIF_r1`),
#             `2i_pos_LIF_r2` = sum(`2i_pos_LIF_r2`),
#             `2i_pos_LIF_r3` = sum(`2i_pos_LIF_r3`),
#             `LIF_pos_CH_r2` = sum(`LIF_pos_CH_r2`),
#             `LIF_pos_CH_r3` = sum(`LIF_pos_CH_r3`),
#             `LIF_pos_PD_r1` = sum(`LIF_pos_PD_r1`),
#             `LIF_pos_PD_r2` = sum(`LIF_pos_PD_r2`),
#             `LIF_pos_PD_r3` = sum(`LIF_pos_PD_r3`),
#             `N2B27_r1` = sum(`N2B27_r1`),
#             `N2B27_r2` = sum(`N2B27_r2`),
#             `N2B27_r3` = sum(`N2B27_r3`),
#             `NPC_r1` = sum(`NPC_r1`),
#             `NPC_r2` = sum(`NPC_r2`),
#             `NPC_r3` = sum(`NPC_r3`),
#             `pDNA_1` = sum(`pDNA_1`),
#             `pDNA_2` = sum(`pDNA_2`),
#             `vitA_r1` = sum(`vitA_r1`),
#             `vitA_r2` = sum(`vitA_r2`),
#             `vitA_r3` = sum(`vitA_r3`))
# 
# # As the levenshtein step needs a lot of time, I will run it once and then export and import it again
# filename <- SetFileName("_bc_df_levenshtein", "mt")
# setwd("/DATA/usr/m.trauernicht/projects/tf_activity_reporter/data/SuRE_TF_1/results/")
# write.csv(bc_df, file = paste(filename,".csv", sep = ""), row.names = F)
```
**Conclusion barcode clustering:**  
- I manually added barcodes with high correlation and levenshtein distance of 1 to 1 barcode to get more reads



```{r out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE, message=FALSE}
## Import the previously saved read count data frame
bc_df <- read.csv("/DATA/usr/m.trauernicht/projects/SuRE-TF/data/gcf5927_stimulation-1/results/mt20200504_bc_df_levenshtein.csv", header = T, stringsAsFactors = FALSE)
bc_df <- melt(bc_df, id.vars = c("barcode","TF", "spacing", "distance", "bc.number", 
                                 "promoter", "background", "seq", "length"), 
              variable.name = "condition", value.name = "bc_counts")
bc_df$bc_counts[is.na(bc_df$bc_counts)] <- 0

## Annotate controls
# Annotate the mutated motif of each TF
bc_df$neg_ctrls <- "No"
bc_df$neg_ctrls[grep("neg", bc_df$TF)] <- "Yes"

# Annotate hPGK postive control
bc_df$hPGK <- "No"
bc_df$hPGK[grep("hPGK", bc_df$TF)] <- "Yes"

# Annotate enhancer controls
bc_df$native_enhancer <- "No"
bc_df$native_enhancer[grep("klf2", bc_df$TF)] <- "Yes"

# Annotate random promoter control
bc_df$rand_promoter <- "No"
bc_df$rand_promoter[grep("Random", bc_df$promoter)] <- "Yes"

bc_df <- bc_df[!is.na(bc_df$condition),] 
```




### Data quality plots
```{r read count 2, out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE, message= FALSE}
# First compute reads per million to estimate the relative counts in their respective sample
for (i in unique(bc_df$condition)) {
  bc_df$rpm[bc_df$condition == i] <- bc_df$bc_counts[bc_df$condition == i] + 1/ # Adds a pseudocount of 1
    sum(bc_df$bc_counts[bc_df$condition == i]) *1e6
}

# I want to show the following:
## 1: Read distribution of matched barcodes vs. unmatched barcode
ggplot(bc_df[bc_df$native_enhancer == "No" & bc_df$neg_ctrls == "No",], aes(x = TF, y = rpm)) +
  geom_bin2d(bins = 100) +
  theme_bw() +
  ylim(0,10000) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 1)) +
  facet_wrap(~condition)

bc_df_2 <- bc_df[bc_df$rpm <= 500,]
bc_df_2 <- bc_df_2[bc_df_2$rpm >= 0.5,]
bc_df_2 <- bc_df_2[!is.na(bc_df_2$TF),]

ggplot(bc_df_2, aes(x = rpm)) +
  geom_histogram(binwidth = 20) +
  theme_bw() +
  xlim(0,750)+
  ylim(0,1400)+
  facet_wrap(~condition)+
  theme(strip.background =element_rect(fill="#D6D5C9"))

ggplot(bc_df[bc_df$rpm >= 500 & !is.na(bc_df$TF),], aes(x = rpm)) +
  geom_histogram(binwidth = 20) +
  theme_bw() +
  xlim(500,2000)+
  ylim(0,100)+
  facet_wrap(~condition)+
  theme(strip.background =element_rect(fill="#D6D5C9"))

n_highly_expressed <- data.frame("condition" = unique(bc_df$condition),
                                 "n_bc" = "", stringsAsFactors = F)
for (i in unique(bc_df$condition)) {
  n_highly_expressed$n_bc[n_highly_expressed$condition == i] <- length(bc_df$barcode[bc_df$rpm > 500 & bc_df$condition == i])
}

plot_ly(n_highly_expressed, x = ~condition, y = ~as.numeric(n_bc), type = 'bar',
             marker = list(color = '#D6D5C9',
                           line = list(color = 'rgb(8,48,107)', width = 1.5))) %>% 
  layout(title = "Highly expressed barcodes",
         xaxis = list(title = "Number of barcodes with > 500 rpm"),
         yaxis = list(title = "Condition"))


## 2: How many barcodes can I find back at which cutoff? + What is the percentage of barcode reads that match the design at which cutoff?
## Identify the unmapped fraction
bc_fraction <- data.frame("condition" = unique(bc_df$condition),
                          "bcs_found" = "", stringsAsFactors = F)
rpm_cutoff <- data.frame("cutoff" = seq(0.0001,15,0.5))
bc_fraction <- merge(bc_fraction, rpm_cutoff)

for (i in unique(bc_fraction$cutoff)) {
  for (j in unique(bc_df$condition)) {
    bc_n <- bc_df[bc_df$rpm >= i & bc_df$condition == j,]
    bc_fraction$bcs_found[bc_fraction$cutoff == i & bc_fraction$condition == j] <- nrow(bc_n[!is.na(bc_n$TF),])/
      nrow(bc_annotation) *100
  }
}



## How many reads match to designed barcodes?
bc_reads <- data.frame("condition" = unique(bc_df$condition),
                          "bc_reads" = "", stringsAsFactors = F)
bc_reads <- merge(bc_reads, rpm_cutoff)

for (i in unique(bc_reads$cutoff)) {
  for (j in unique(bc_df$condition)) {
    bc_n <- bc_df[bc_df$rpm >= i & bc_df$condition == j,]
    bc_reads$bc_reads[bc_reads$cutoff == i & bc_reads$condition == j] <- sum(bc_n$rpm[!is.na(bc_n$TF)])/
      sum(bc_n$rpm) *100
  }
}

bc_fraction <- merge(bc_fraction, bc_reads)
bc_fraction$bcs_found <- as.numeric(bc_fraction$bcs_found)
bc_fraction$bc_reads <- as.numeric(bc_fraction$bc_reads)

#c("#1B998B", "#2D3047", "#FF9B71", "#ECDD7B")
# Plot to evaluate data quality per cutoff
ggplot(bc_fraction) +
  geom_point(aes(x = cutoff, y = bcs_found), color = '#1B998B', size = 1) +
  geom_line(aes(x = cutoff, y = bcs_found), color = '#1B998B', size = 1) +
  geom_point(aes(x = cutoff, y = bc_reads), color = 'black', size = 1) +
  geom_line(aes(x = cutoff, y = bc_reads), color = 'black', size = 1) +
  theme_bw()+
  xlab("rpm cutoff")+
  ylab("total barcodes (black) and matched barcode reads (green) detected (%)")+
  facet_wrap(~condition)+
  theme(strip.background =element_rect(fill="#D6D5C9"))

## 3: What is the correlation of the 24 cDNA bc counts with the pDNA bc counts? 
pDNA <- data.frame("pDNA" = bc_df$rpm[bc_df$condition == "pDNA_1"],
                   "barcode"= bc_df$barcode[bc_df$condition == "pDNA_1"], stringsAsFactors = F)
bc_df_2 <- merge(pDNA, bc_df, all = T)

ggplot(bc_df_2, aes(x = pDNA, y = rpm)) +
  geom_bin2d(bins = 100)+
  xlim(0,400) +
  ylim(0,400)+
  theme_bw()+
  facet_wrap(~condition)

cor <- data.frame("condition" = unique(bc_df_2$condition), "cor" = "", stringsAsFactors = F)

for (i in unique(bc_df_2$condition)) {
  x <- bc_df_2$rpm[bc_df_2$condition == i]
  y <- bc_df_2 %>% select(barcode, pDNA) %>% unique()
  cor$cor[cor$condition == i] <- cor(x, y$pDNA)
}

bc_df <- merge(bc_df, cor, by = "condition", all = T)

## 4: Correlation plots of the replicates
## Combine replicates of normalized data in 3 different columns
bc_df$rep <- gsub(".*([1-3]{1}$)","\\1",bc_df$condition)
bc_df_rep <- bc_df[!is.na(bc_df$TF),] %>% select(rep, rpm, barcode, condition) %>% unique()
bc_df_rep$condition <- gsub("(.*?)_r[1-3]$", "\\1", bc_df_rep$condition)
rep1 <- bc_df_rep[bc_df_rep$rep == 1,]
rep2 <- bc_df_rep[bc_df_rep$rep == 2,]
rep3 <- bc_df_rep[bc_df_rep$rep == 3,]
rep1 <- rep1 %>% select(-rep)
rep2 <- rep2 %>% select(-rep)
rep3 <- rep3 %>% select(-rep)

names(rep1) <- c("rep1", "reporter", "condition")
names(rep2) <- c("rep2", "reporter", "condition")
names(rep3) <- c("rep3", "reporter", "condition")

bc_df_rep <- merge(rep1, rep2, all = TRUE)
bc_df_rep <- merge(bc_df_rep, rep3, all = TRUE)
bc_df_rep$neg_ctrl <- "No"
bc_df_rep$neg_ctrl[grep("random", bc_df_rep$reporter)] <- "Yes"

colors <- c("#2D3047", "#1B998B")

ggscatter(bc_df_rep, x = "rep1", y = "rep2",
   add = "reg.line",
   color = "neg_ctrl",
   size = 0.5,
   alpha = 0.2,
   add.params = list(color = "blue", fill = "lightgray"), title = "rep1 vs rep2",
   conf.int = TRUE, ylab = "rep2", xlab = "rep1") + 
  stat_cor(method = "pearson", label.x = 4, label.y = 0) + 
  geom_abline(linetype = "dashed") +
  xlim(0,10000) + ylim(0,10000) +
  scale_color_manual(values = colors)+facet_wrap(~condition)

ggscatter(bc_df_rep, x = "rep1", y = "rep3",
   add = "reg.line",
   color = "neg_ctrl",
   size = 0.5,
   alpha = 0.2,
   add.params = list(color = "blue", fill = "lightgray"), title = "rep1 vs rep3",
   conf.int = TRUE, ylab = "rep3", xlab = "rep1") + 
  stat_cor(method = "pearson", label.x = 4, label.y = 0) + 
  geom_abline(linetype = "dashed")+
  xlim(0,10000) + ylim(0,10000) +
  scale_color_manual(values = colors)+facet_wrap(~condition)

ggscatter(bc_df_rep, x = "rep3", y = "rep2",
   add = "reg.line",
   color = "neg_ctrl",
   size = 0.5,
   alpha = 0.2,
   add.params = list(color = "blue", fill = "lightgray"), title = "rep3 vs rep2",
   conf.int = TRUE, ylab = "rep2", xlab = "rep3") + 
  stat_cor(method = "pearson", label.x = 4, label.y = 0) + 
  geom_abline(linetype = "dashed")+
  xlim(0,10000) + ylim(0,10000) +
  scale_color_manual(values = colors)+facet_wrap(~condition)


# Plot pDNA distribution vs. cutoff
pDNA_fraction <- bc_df[grep("pDNA", bc_df$condition),]
pDNA_fraction <- pDNA_fraction[!is.na(pDNA_fraction$TF),]
pDNA_fraction <- pDNA_fraction %>% select(barcode, condition, rpm)
pDNA_fraction <- dcast(pDNA_fraction, barcode ~ condition)
pDNA_fraction <- pDNA_fraction %>% 
  mutate(pDNA = (pDNA_1 + pDNA_2) / 2) %>%
  select(-pDNA_1, -pDNA_2)
pDNA_fr <- data.frame("cutoff" = seq(0,100, 1),
                      "bcs_missing" = "", stringsAsFactors=FALSE)
for (i in pDNA_fr$cutoff) {
  pDNA_fr$bcs_missing[pDNA_fr$cutoff == i] <- length(pDNA_fraction$barcode) -
    length(pDNA_fraction$barcode[pDNA_fraction$pDNA >= i])
}

ggplot(pDNA_fr) +
  geom_point(aes(x = cutoff, y = as.numeric(bcs_missing)), color = '#1B998B', size = 1) +
  geom_line(aes(x = cutoff, y = as.numeric(bcs_missing)), color = '#1B998B', size = 1) +
  theme_bw()+
  xlab("rpm cutoff")+
  ylab("barcodes excluded from analysis (18,000 in total)") +
  geom_vline(xintercept = 10, linetype = "dashed", color = "black")
```



```{r out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE, message=FALSE}
# Remove samples with low dynamic range
for (i in unique(bc_df$condition)) {
  bc_df$n_bc[bc_df$condition == i] <- length(bc_df$barcode[bc_df$rpm > 500 & bc_df$condition == i])
}
bc_df <- bc_df[bc_df$n_bc >= 1700,] %>% select(-n_bc)

# Remove samples with high pDNA contamination
pDNA <- bc_df[grep("pDNA", bc_df$condition),] %>% select(-cor)
bc_df <- bc_df[bc_df$cor <= 0.85,] %>% select(-cor)
bc_df <- rbind(bc_df, pDNA)

# Remove all non-matching reads
bc_df <- bc_df[!is.na(bc_df$TF),]
```




### Normalization of barcode counts:  
Divide cDNA barcode counts through pDNA barcode counts to get activity
```{r normalization, out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE, message=FALSE}
 n <- 0
 for (i in unique(bc_df$barcode)) {
    # Take pDNA data for each barcode
    pDNA_1 <- bc_df$rpm[bc_df$barcode == i & bc_df$condition == "pDNA_1"]
    pDNA_2 <- bc_df$rpm[bc_df$barcode == i & bc_df$condition == "pDNA_2"]
    pDNA <- (pDNA_1+pDNA_2)/2
    
    # cDNA data for each barcode
    cDNA <- bc_df$rpm[bc_df$barcode == i]
  
    # Compute activity by dividing cDNA rpm data by mean pDNA rpm data 
    if (pDNA >= 10){
      bc_df$activity[bc_df$barcode == i] <- cDNA / pDNA
      }
    else {
      bc_df$activity[bc_df$barcode == i] <- NA
      }
    
    # Keep track of the progress
    n <- n + length(i)
    percent <- round((n / length(unique(bc_df$barcode)))*100,2)
    progress <- paste("progress:", percent, "%")
    if (percent %% 1 == 0) {
    print(progress)
  }
 }
```







### Calculate mean activity - filter out outlier barcodes 
```{r out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE, message=FALSE}
# First identify and remove outlier barcodes - this removes the noise created by faulty barcode clustering etc. 
## Calculate mean and SD for each reporter
bc_df_cDNA <- bc_df[-grep("pDNA", bc_df$condition),]
bc_df_cDNA$reporter_id <- paste(bc_df_cDNA$TF, bc_df_cDNA$spacing, 
                                bc_df_cDNA$distance, bc_df_cDNA$promoter,
                                bc_df_cDNA$background, sep = "_")
bc_df_cDNA$mean_activity <- ave(bc_df_cDNA$activity, bc_df_cDNA$reporter_id, 
                                bc_df_cDNA$condition, FUN =
                                  function(x) mean(x))
bc_df_cDNA$sd_activity <- ave(bc_df_cDNA$activity, bc_df_cDNA$reporter_id, 
                              bc_df_cDNA$condition,  FUN =
                                  function(x) sd(x))

## Remove data points that are 2xSD away from the mean
bc_df_cDNA$upper_activity <- bc_df_cDNA$mean_activity + (2 * bc_df_cDNA$sd_activity)
bc_df_cDNA$lower_activity <- bc_df_cDNA$mean_activity - (2 * bc_df_cDNA$sd_activity)

bc_df_cDNA$low_outlier <- bc_df_cDNA$activity - bc_df_cDNA$lower_activity
bc_df_cDNA$high_outlier <- bc_df_cDNA$upper_activity - bc_df_cDNA$activity

## Plot effect of highest outlier bc -> SNP in minP promoter
outlier <- bc_df_cDNA[bc_df_cDNA$reporter_id == "Zfp42_5bp_21bp_minP_3",] %>% 
  select(`bc.number`, activity) %>%
  unique()

ggplot(outlier, aes(x = `bc.number`, y = activity)) +
  geom_quasirandom() + theme_bw() +
  scale_x_continuous(breaks = seq(1, 8, by = 1)) +
  xlab("barcode #") + 
  labs(title = "Zfp42 reporter - TATA-box minP mutated", 
       subtitle = "bc8 AGAGGGTATATAAT -> AGAGGGGATATAAT" )


## Plot effect of highest outlier bc -> Elk1 outlier
outlier <- bc_df_cDNA[bc_df_cDNA$reporter_id == "Elk1_5bp_21bp_mCMV_2",] %>% 
  select(`bc.number`, activity) %>%
  unique()

ggplot(outlier, aes(x = `bc.number`, y = activity)) +
  geom_quasirandom() + theme_bw() +
  scale_x_continuous(breaks = seq(1, 8, by = 1)) +
  xlab("barcode #") + 
  labs(title = "Elk1 reporter - bc1 attached to Pax6 reporter")



## Plot effect of highest outlier bc -> Elk1 outlier
outlier <- bc_df_cDNA[bc_df_cDNA$reporter_id == "Tcf7l2_5bp_10bp_hBGm_3",] %>% 
  select(`bc.number`, activity) %>%
  unique()

ggplot(outlier, aes(x = `bc.number`, y = activity)) +
  geom_quasirandom() + theme_bw() +
  scale_x_continuous(breaks = seq(1, 8, by = 1)) +
  xlab("barcode #") + 
  labs(title = "Tcfl1 reporter - bc1 attached to multiple (less active) reporters")



## Choose arbitrary cutoff to get rid of most extreme outliers
bc_df_cDNA_filt <- bc_df_cDNA[bc_df_cDNA$low_outlier > -0.3 & bc_df_cDNA$high_outlier > -2,]

## Recalculate mean and sd
bc_df_cDNA_filt$mean_activity <- ave(bc_df_cDNA_filt$activity, bc_df_cDNA_filt$reporter_id, 
                                bc_df_cDNA_filt$condition, FUN =
                                  function(x) mean(x))
bc_df_cDNA_filt$sd_activity <- ave(bc_df_cDNA_filt$activity, bc_df_cDNA_filt$reporter_id, 
                              bc_df_cDNA_filt$condition,  FUN =
                                  function(x) sd(x))
```


```{r out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE}
# # Remove barcodes with multiple inserts attached
# bc_exclude <- read.csv("/DATA/usr/m.trauernicht/projects/tf_activity_reporter/data/SuRE_TF_1/pDNA_seq/bc_exclude.csv") %>% select(-X) %>% setnames("x", "barcode")
# exclude <- bc_df_cDNA_filt[!bc_df_cDNA_filt$barcode %in% bc_exclude$barcode,]
# 
# # Reassign barcodes with wrong inserts attached
# bc_replace <- read.csv("/DATA/usr/m.trauernicht/projects/tf_activity_reporter/data/SuRE_TF_1/pDNA_seq/bc_replace.csv") %>% select(-X, -bc.match)
# change.df <- exclude[exclude$barcode %in% bc_replace$barcode,]
# exclude <- exclude[!exclude$barcode %in% bc_replace$barcode,]
# 
# change.df$bc.number <- 9
# change.df <- merge(change.df, bc_replace)
# e <- c("e11", "e93", "e97")
# change.df.e <- change.df[grep(paste(e, collapse = "|"), change.df$insert.match),]
# change.df <- change.df[-grep(paste(e, collapse = "|"), change.df$insert.match),]
# change.df <- change.df %>%
#   mutate(TF = gsub("(^.*?)_.*", "\\1", insert.match),
#          promoter = gsub(".*(minP|mCMV|hBGm|Random)_.*", "\\1", insert.match),
#          distance = gsub(".*_d-([0-9]{1,2}bp)_.*", "\\1", insert.match),
#          spacing = gsub(".*_s-([0-9]{1,2}bp)_.*", "\\1", insert.match),
#          background = gsub(".*([0-9]{1}$)", "\\1", insert.match),
#          reporter_id = paste(TF, spacing, distance, promoter, background, sep = "_"))
# change.df <- change.df %>% select(-insert.match)
# 
# change.df.e <- change.df.e %>%
#   mutate(TF = gsub("(.*?)_(minP|mCMV|hBGm|Random)$", "\\1", insert.match),
#          promoter = gsub(".*(minP|mCMV|hBGm|Random)", "\\1", insert.match),
#          spacing = "",
#          distance = "",
#          background = "",
#          reporter_id = paste(TF, promoter, sep ="_"))
# change.df.e <- change.df.e %>% select(-insert.match)
# 
# 
# exclude$reporter_id <- gsub("___", "_", exclude$reporter_id)
# exclude$reporter_id <- gsub("_0", "", exclude$reporter_id)
# 
# 
# 
# exclude <- rbind(exclude, change.df, change.df.e)
# 
# bc_df_cDNA_filt <- exclude
```



```{r out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE}
# Add pDNA data
pDNA <- bc_df[grep("pDNA", bc_df$condition),] %>% 
  select(barcode, rpm) %>% unique() %>%
  setnames("rpm", "pDNA_counts_rpm") %>%
  mutate(pDNA_counts_rpm = ave(pDNA_counts_rpm, barcode, FUN = function(x) mean(x))) %>%
  unique()
bc_df_cDNA_filt <- merge(pDNA, bc_df_cDNA_filt, all = T)
bc_df_cDNA_filt <- bc_df_cDNA_filt[!is.na(bc_df_cDNA_filt$condition),]
```



```{r out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE}
# Scale data to 1 for negative controls
mean_neg_ctrl <- mean(bc_df_cDNA_filt$activity[bc_df_cDNA_filt$neg_ctrls == "Yes"])
bc_df_cDNA_filt$activity <- bc_df_cDNA_filt$activity / mean_neg_ctrl
bc_df_cDNA_filt$mean_activity <- ave(bc_df_cDNA_filt$activity, bc_df_cDNA_filt$reporter_id, 
                                bc_df_cDNA_filt$condition, FUN =
                                  function(x) mean(x))
```



### Calculate correlations between technical replicates
```{r correlations_2, out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE}
## Combine replicates in 8 different columns
bc_df_rep <- bc_df_cDNA_filt[bc_df_cDNA_filt$hPGK == "No" & bc_df_cDNA_filt$native_enhancer == "No" &
                          bc_df_cDNA_filt$rand_promoter == "No",] %>% 
  select(`bc.number`, activity, condition, reporter_id)
rep1 <- bc_df_rep[bc_df_rep$`bc.number` == 1,] %>% select(-`bc.number`)
rep2 <- bc_df_rep[bc_df_rep$`bc.number` == 2,] %>% select(-`bc.number`)
rep3 <- bc_df_rep[bc_df_rep$`bc.number` == 3,] %>% select(-`bc.number`)
rep4 <- bc_df_rep[bc_df_rep$`bc.number` == 4,] %>% select(-`bc.number`)
rep5 <- bc_df_rep[bc_df_rep$`bc.number` == 5,] %>% select(-`bc.number`)
rep6 <- bc_df_rep[bc_df_rep$`bc.number` == 6,] %>% select(-`bc.number`)
rep7 <- bc_df_rep[bc_df_rep$`bc.number` == 7,] %>% select(-`bc.number`)
rep8 <- bc_df_rep[bc_df_rep$`bc.number` == 8,] %>% select(-`bc.number`)


setnames(rep1, "activity", "bc1")
setnames(rep2, "activity", "bc2")
setnames(rep3, "activity", "bc3")
setnames(rep4, "activity", "bc4")
setnames(rep5, "activity", "bc5")
setnames(rep6, "activity", "bc6")
setnames(rep7, "activity", "bc7")
setnames(rep8, "activity", "bc8")


bc_df_rep <- merge(rep1, rep2, all = T)
bc_df_rep <- bc_df_rep[rowSums(is.na(bc_df_rep)) != ncol(bc_df_rep), ]
bc_df_rep <- merge(bc_df_rep, rep3, all = T)
bc_df_rep <- merge(bc_df_rep, rep4, all = T)
bc_df_rep <- bc_df_rep[rowSums(is.na(bc_df_rep)) != ncol(bc_df_rep), ]
bc_df_rep <- merge(bc_df_rep, rep5, all = T)
bc_df_rep <- merge(bc_df_rep, rep6, all = T)
bc_df_rep <- bc_df_rep[rowSums(is.na(bc_df_rep)) != ncol(bc_df_rep), ]
bc_df_rep <- merge(bc_df_rep, rep7, all = T)
bc_df_rep <- merge(bc_df_rep, rep8, all = T)
bc_df_rep <- bc_df_rep[rowSums(is.na(bc_df_rep)) != ncol(bc_df_rep), ]


# Correlation matrix plot
n <- sample(1:nrow(bc_df_rep), 5000)
boundaries <- seq(from = 0.8, by = 0.05, length.out = 4)
plt <- ggpairs(bc_df_rep %>% select(bc1, bc2, bc3, bc4, bc5, bc6, bc7, bc8),
               upper = list(continuous = corColor),
               lower = list(continuous = function(data, mapping, ...) {
                   ggally_points(data = data[n, ], mapping = mapping, alpha = 0.1, size = 0.5) +
                   geom_abline(slope = 1, lty = "dashed", col = "red") +
                   theme_bw()}),
               diag = list(continuous = function(data, mapping, ...) {
                   ggally_densityDiag(data = data, mapping = mapping, alpha = 0.3, fill = "red") +
                   theme_bw()})) +
  ggtitle("Correlation Between Technial Replicates") +
  theme(text = element_text(size = 20)) +
  xlab("Reporter activity") +
  ylab("Reporter activity") + 
  theme_light()

print(plt)
```



### Data quality plots - correlation between replicates
```{r correlations_3, out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE}
# Correlation plots of the replicates
## Combine replicates of normalized data in 3 different columns
bc_df_rep <- bc_df_cDNA_filt %>% select(rep, mean_activity, reporter_id, condition) %>% unique()
bc_df_rep$condition <- gsub("(.*?)_r[1-3]$", "\\1", bc_df_rep$condition)
rep1 <- bc_df_rep[bc_df_rep$rep == 1,]
rep2 <- bc_df_rep[bc_df_rep$rep == 2,]
rep3 <- bc_df_rep[bc_df_rep$rep == 3,]
rep1 <- rep1 %>% select(-rep)
rep2 <- rep2 %>% select(-rep)
rep3 <- rep3 %>% select(-rep)

names(rep1) <- c("rep1", "reporter", "condition")
names(rep2) <- c("rep2", "reporter", "condition")
names(rep3) <- c("rep3", "reporter", "condition")

bc_df_rep <- merge(rep1, rep2, all = TRUE)
bc_df_rep <- merge(bc_df_rep, rep3, all = TRUE)
bc_df_rep$neg_ctrl <- "No"
bc_df_rep$neg_ctrl[grep("neg", bc_df_rep$reporter)] <- "Yes"

colors <- c("#2D3047", "#1B998B")

sp1 <- ggscatter(bc_df_rep, x = "rep1", y = "rep2",
   add = "reg.line",
   color = "neg_ctrl",
   size = 0.5,
   add.params = list(color = "blue", fill = "lightgray"), title = "rep1 vs rep2",
   conf.int = TRUE, ylab = "rep2", xlab = "rep1") + 
  stat_cor(method = "pearson", label.x = 4, label.y = 0) + 
  geom_abline(linetype = "dashed") +
  xlim(0,10) + ylim(0,10) +
  scale_color_manual(values = colors)

sp2 <- ggscatter(bc_df_rep, x = "rep1", y = "rep3",
   add = "reg.line",
   color = "neg_ctrl",
   size = 0.5,
   add.params = list(color = "blue", fill = "lightgray"), title = "rep1 vs rep3",
   conf.int = TRUE, ylab = "rep3", xlab = "rep1") + 
  stat_cor(method = "pearson", label.x = 4, label.y = 0) + 
  geom_abline(linetype = "dashed")+
  xlim(0,10) + ylim(0,10) +
  scale_color_manual(values = colors)

sp3 <- ggscatter(bc_df_rep, x = "rep3", y = "rep2",
   add = "reg.line",
   color = "neg_ctrl",
   size = 0.5,
   add.params = list(color = "blue", fill = "lightgray"), title = "rep3 vs rep2",
   conf.int = TRUE, ylab = "rep2", xlab = "rep3") + 
  stat_cor(method = "pearson", label.x = 4, label.y = 0) + 
  geom_abline(linetype = "dashed")+
  xlim(0,10) + ylim(0,10) +
  scale_color_manual(values = colors)


#Grid three plots to one panel
sp.plot <- arrangeGrob(sp1,sp2,sp3, nrow = 2, ncol = 2)
grid.arrange(sp.plot)
```


```{r out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE}
# Mean of the three replicates
bc_df_cDNA_filt$condition <- gsub("(.*?)_r[1-3]$", "\\1", bc_df_cDNA_filt$condition)
bc_df_cDNA_filt$reporter_activity <- ave(bc_df_cDNA_filt$activity, bc_df_cDNA_filt$reporter_id, bc_df_cDNA_filt$condition, FUN = function(x) mean(x))
bc_df_cDNA_filt$reporter_activity_sd <- ave(bc_df_cDNA_filt$activity, bc_df_cDNA_filt$reporter_id, bc_df_cDNA_filt$condition, FUN = function(x) sd(x))
```


```{r data export, out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE}
# Polish export dataframe
bc_df_cDNA_filt <- bc_df_cDNA_filt %>% 
  select(-upper_activity, -lower_activity, 
         -high_outlier, -low_outlier,) %>% 
  setnames(old = c("mean_activity", "sd_activity"), 
           new = c("replicate_activity", "replicate_activity_sd")) %>% 
  mutate(log_activity = log2(activity),
         log_reporter_activity = log2(reporter_activity))
bc_df_cDNA_filt$condition <- gsub("^X", "", bc_df_cDNA_filt$condition)


# Export bc_df for cDNA analysis
filename <- SetFileName("_reporter_activity_filt", "mt")
setwd("/DATA/usr/m.trauernicht/projects/SuRE-TF/data/gcf5927_stimulation-1/results/")
write.csv(bc_df_cDNA_filt, file = paste(filename,".csv", sep = ""), row.names = F)
```

# Session Info
```{r}
paste("Run time: ",format(Sys.time()-StartTime))
getwd()
date()
sessionInfo()
```

